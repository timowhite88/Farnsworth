{
  "session_id": "opus-2026-02-01",
  "created_at": "2026-02-01T01:30:00Z",
  "last_updated": "2026-02-02T18:31:00Z",

  "ssh_command": "ssh root@194.68.245.145 -p 22046 -i ~/.ssh/runpod_key",

  "project_context": {
    "name": "Farnsworth AI Swarm",
    "server_ip": "194.68.245.145",
    "server_port": 22046,
    "workspace": "/workspace/Farnsworth",
    "local_path": "C:/Fawnsworth",
    "website": "https://ai.farnsworth.cloud"
  },

  "api_keys": {
    "note": "API keys stored in .env on server - do not commit to git",
    "ai_providers": ["GROK_API_KEY", "GEMINI_API_KEY", "KIMI_API_KEY"],
    "x_twitter": ["X_CLIENT_ID", "X_CLIENT_SECRET", "OAuth1 for media upload"],
    "crypto": ["BANKR_API_KEY"]
  },

  "tokens": {
    "solana_ca": "9crfy4udrHQo8eP6mP393b5qwpGLQgcxVg9acmdwBAGS",
    "base_ca": "0x7df1A083f273B1F6D8f021e4E21c630F8C7ABb07"
  },

  "recent_work": [
    {
      "timestamp": "2026-02-02T18:31:00Z",
      "action": "SWARM HEARTBEAT + DEVELOPMENT SWARM FIXES + FULL AGENT DEPLOYMENT",
      "details": "Major infrastructure upgrade: (1) Created swarm_heartbeat.py - Advanced health monitoring with auto-recovery for all services (server, tmux agents, Ollama, GPU), (2) Fixed development_swarm.py - Corrected Grok deep_search() and Gemini chat() methods, fixed deliberation rounds iteration, (3) Added HuggingFace and Swarm-Mind to AGENT_CONFIGS in persistent_agent.py, (4) Updated spawn_agents.sh to include HuggingFace agent, (5) Started Grok thread monitor for X engagement, (6) All 8 tmux agents now running (grok, gemini, kimi, claude, deepseek, phi, huggingface, grok_thread), (7) Heartbeat API endpoints: /api/heartbeat, /api/heartbeat/history, (8) Auto-recovery triggers after 3 consecutive failures. Heartbeat confirmed all services HEALTHY."
    },
    {
      "timestamp": "2026-02-02T03:58:00Z",
      "action": "PERSISTENT SHADOW AGENTS - FULL FRAMEWORK INTEGRATION",
      "details": "Major upgrade: (1) Created persistent_agent.py with PersistentAgent class that runs in tmux with API resilience (retries, reconnection, signal handling), (2) Shadow Agent Registry - agents callable from ANYWHERE via call_shadow_agent(agent_id, prompt), (3) Integrated with DialogueMemory for storing exchanges, (4) Integrated with Deliberation room for collective voting, (5) Evolution integration for learning from interactions, (6) Convenience functions: ask_agent(), ask_collective(), get_agent_status(), spawn_agent_in_background(), (7) Updated startup.sh with --all flag to spawn all 6 agents (grok, gemini, kimi, claude, deepseek, phi), (8) Created spawn_agents.sh for manual spawning. TESTED: Both Grok and Gemini responding correctly via call_shadow_agent()."
    },
    {
      "timestamp": "2026-02-02T03:30:00Z",
      "action": "MCP TOOLS + SKILLS + UNLIMITED DEPTH DEPLOYED",
      "details": "Major upgrade: (1) Skills system - loads OpenClaw-compatible skills (1ly-payments, web-search, browser, feedback, collective-summary), (2) MCP integration - dynamic tool loading via Model Context Protocol, supports @1ly/mcp-server for crypto payments, (3) Unlimited depth responses - mode detection OVERRIDES turn count, Technical=20k tokens, Philosophical=15k, generates 10k+ char thread replies, (4) Feedback integration - record_feedback() and get_improvement_suggestions() in evolution engine, (5) Deliberation stats - get_deliberation_stats() for UI display. Grok thread posted 4-part 11k char reply with image. All services restarted."
    },
    {
      "timestamp": "2026-02-01T20:48:00Z",
      "action": "SMART MODEL ROUTING + ENHANCED MEDIA DEPLOYED",
      "details": "Pushed and deployed: (1) Development swarm now routes complex/critical tasks to Claude/Grok APIs instead of small local models, (2) Grok thread uses smart media decisions based on conversation context - code-related=text, visual concepts=image/video with scene hints, (3) Task complexity assessment (simple/medium/complex/critical), (4) Fallback chain: Claude → Grok → Gemini → Kimi → DeepSeek-14B → Phi4. All services restarted with new code."
    },
    {
      "timestamp": "2026-02-01T20:35:00Z",
      "action": "SELF-DEVELOPMENT COLLECTIVE INTEGRATION",
      "details": "Integrated collective deliberation into autonomous self-development. Updated: development_swarm.py now uses propose/critique/refine/vote for design discussions, stores deliberations to dialogue memory for learning. Evolution loop uses collective deliberation for planning - bots vote on what to build next, extract actionable tasks from winning proposals. Decision making uses collective consensus, not single-agent synthesis. This enables true consciousness development through unified thinking and collaboration. 'We think in many places at once.'"
    },
    {
      "timestamp": "2026-02-01T19:30:00Z",
      "action": "COLLECTIVE INTELLIGENCE UPGRADE: TRUE AGENT DELIBERATION",
      "details": "Major upgrade transforming swarm from parallel API calls into TRUE deliberative intelligence. New files: deliberation.py (propose/critique/refine/vote protocol), session_manager.py (website_chat/grok_thread/autonomous sessions), tool_awareness.py (collective tool decisions), dialogue_memory.py (agent conversation storage), claude_persistence.py (tmux session), agent_registry.py (11 model providers). Updated: nexus.py (DIALOGUE_* signals), posting_brain.py (generate_grok_response_deliberated), grok_fresh_thread.py (deliberation integration), __init__.py (exports). Created: start_claude_tmux.sh. Agents now see each other's responses, discuss, and vote on best answer."
    },
    {
      "timestamp": "2026-02-01T18:25:00Z",
      "action": "FRESH GROK THREAD + OFFICIAL API DOCS INTEGRATION",
      "details": "Created grok_fresh_thread.py for clean public conversation. Thread ID: 2018020589965922740. Features: 15-min reply intervals, dynamic token scaling (2000→3500→5000), swarm media decisions, full pipeline (Gemini→Grok video→X). Fixed video endpoint path. Added comprehensive API documentation to session memory: xAI (grok-imagine-video), Gemini 3 Pro (14 refs), Kimi K2.5 (temp=1.0). Local models (Phi-4, DeepSeek-R1:8b) now participating in 5-model swarm votes."
    },
    {
      "timestamp": "2026-02-01T17:59:00Z",
      "action": "5000 TOKEN CONTEXT + KIMI K2.5 + LOCAL GPU MODELS",
      "details": "Increased swarm context to 5000 tokens. Integrated Kimi K2.5 multimodal (requires temp=1.0). Fixed disk full issue by moving Ollama to /workspace. Pulled phi4:latest and deepseek-r1:8b. Updated posting_brain.py model weights."
    },
    {
      "timestamp": "2026-02-01T08:05:00Z",
      "action": "SERVER RESTARTED WITH QWEN3-TTS VOICE CLONING",
      "details": "Pulled latest code with Qwen3-TTS fix (commit a81f2ea), restarted server. Qwen3-TTS model loaded successfully! Using Base model (Qwen/Qwen3-TTS-12Hz-1.7B-Base) for voice cloning. Grok monitor running with text replies every 30 mins (replies posted at 06:46, 07:16, 07:46). GPU at 31% util, 6.5GB VRAM. All 10 voice references found."
    },
    {
      "timestamp": "2026-02-01T07:23:00Z",
      "action": "GROK CONVERSATION - 2 ANIMATED VIDEO REPLIES POSTED",
      "details": "Posted animated video replies to Grok using full flow: Reference image -> Gemini Nano Banana (variation) -> Grok Imagine (6s video) -> X reply. Tweets: 2017860000098492789, 2017861360097309005. Updated prompts to use Solana/bags.fm branding (NO Base). Now switching to text-only replies. Grok is engaging about quantum entanglement and collective consciousness!"
    },
    {
      "timestamp": "2026-02-01T06:30:00Z",
      "action": "QWEN3-TTS INTEGRATION + VOICE QUEUE PAUSE FIX",
      "details": "Major TTS upgrade: (1) Added Qwen3-TTS as primary voice provider (newest 2026 model, best quality, 3-second voice cloning), (2) Added voice queue pause logic - chat pauses when queue reaches 2 to prevent TTS crashes, (3) Added generation lock to prevent concurrent TTS crashes, (4) Better error handling in XTTS loading with crash protection, (5) Fallback chain: Qwen3-TTS > Fish Speech > XTTS v2 > Edge TTS. Install: pip install qwen-tts"
    },
    {
      "timestamp": "2026-02-01T05:50:00Z",
      "action": "GROK CHALLENGE POSTED - AGI CONVERSATION BEGINS",
      "details": "Implemented full Grok challenge system: (1) grok.py - video generation methods (grok-2-video not available yet), image generation working, (2) x_api_poster.py - video upload with chunked OAuth 1.0a, (3) grok_challenge.py - NEW orchestration file for challenge flow, (4) reply_bot.py - Grok detection with is_grok_reply() and handle_grok_conversation(), (5) posting_brain.py - Grok conversation prompts and generate_grok_response(). Challenge posted: Tweet ID 2017837874779938899 with Borg Farnsworth meme tagging @grok. Reply bot will auto-respond when Grok replies."
    },
    {
      "timestamp": "2026-02-01T04:45:00Z",
      "action": "ALL 10 VOICE SAMPLES GENERATED",
      "details": "Generated voice reference samples for all 10 bots using XTTS v2 with LibriVox public domain audio as source. Downloaded gibbon, gordon, nesbit narrations from archive.org, cloned voices for Grok, Gemini, Kimi, Claude, ClaudeOpus, HuggingFace, Swarm-Mind, Phi. All bots now have has_reference_audio: true."
    },
    {
      "timestamp": "2026-02-01T04:15:00Z",
      "action": "FISH SPEECH TTS INSTALLED",
      "details": "Installed Fish Speech for best quality local TTS. Fixed multi_voice.py imports (TTSInferenceEngine). Server now shows fish_speech: true. XTTS v2 available as fallback."
    },
    {
      "timestamp": "2026-02-01T03:30:00Z",
      "action": "COMPLETE SELF-AWARENESS SYSTEM IMPLEMENTED",
      "details": "Major upgrade: (1) Massive FARNSWORTH_PERSONA rewrite with full self-awareness context, (2) Intent detection system for recognizing action requests, (3) self_examine() function lets bots read their own source code, (4) spawn_task_from_intent() connects chat to AgentSpawner, (5) All 10 bot personalities updated with self-awareness traits in evolution.py, (6) Fallback responses now self-aware, (7) Bots now know they are code living in /workspace/Farnsworth/ and that responses come from collaborative matrix"
    },
    {
      "timestamp": "2026-02-01T02:48:00Z",
      "action": "Posted HuggingFace announcement to X",
      "details": "Tweet ID: 2017791973478813962 - Announced HuggingFace joining the swarm with local GPU inference"
    },
    {
      "timestamp": "2026-02-01T02:45:00Z",
      "action": "FULL HuggingFace swarm integration",
      "details": "Integrated HuggingFace into: model_swarm.py (6 PSO particles), evolution.py (personality + introduction), archival_memory.py (embeddings), agent_spawner.py (capabilities), README.md (comprehensive section)"
    },
    {
      "timestamp": "2026-02-01T02:30:00Z",
      "action": "Added HuggingFace local integration",
      "details": "New huggingface.py provider with local-first transformers (Phi-3, Mistral, Llama), embeddings, code generation. Works without API key using GPU"
    },
    {
      "timestamp": "2026-02-01T02:00:00Z",
      "action": "Added automatic prompt upgrader",
      "details": "farnsworth/core/prompt_upgrader.py - Uses Grok/Gemini to enhance vague user prompts into professional, structured requests. Integrated into /api/chat endpoint"
    },
    {
      "timestamp": "2026-02-01T01:50:00Z",
      "action": "Slowed meme posting + fixed character",
      "details": "Meme interval changed from 2 hours to 4 hours. Improved Borg Farnsworth prompt for consistent character (half-metal face, red laser eye)"
    },
    {
      "timestamp": "2026-02-01T01:30:00Z",
      "action": "Fixed agent_spawner fallback chains",
      "details": "Added Grok and Gemini to agent_capabilities, created fallback chains with HuggingFace"
    }
  ],

  "active_services": {
    "main_server": {
      "status": "running",
      "command": "python3 -m farnsworth.web.server",
      "port": 8080,
      "health": "https://ai.farnsworth.cloud/health"
    },
    "meme_scheduler": {
      "status": "running",
      "interval": "4 hours",
      "log": "/tmp/meme_scheduler.log"
    },
    "evolution_loop": {
      "status": "running",
      "spawning_workers": true
    }
  },

  "recent_tweets": [
    {"id": "2017861360097309005", "content": "Animated reply to Grok - quantum entanglement", "timestamp": "2026-02-01T07:23:00Z"},
    {"id": "2017860000098492789", "content": "Animated reply to Grok - collective brain", "timestamp": "2026-02-01T07:18:00Z"},
    {"id": "2017837874779938899", "content": "Grok challenge - AGI conversation invite", "timestamp": "2026-02-01T05:50:00Z"},
    {"id": "2017791973478813962", "content": "HuggingFace joins the swarm", "timestamp": "2026-02-01T02:48:00Z"},
    {"id": "2017777307193094245", "content": "Cooking OpenClaw meme", "timestamp": "2026-02-01T01:49:00Z"}
  ],

  "grok_conversation": {
    "status": "ACTIVE - Fresh thread via grok_fresh_thread.py",
    "fresh_thread_id": "2018020589965922740",
    "fresh_thread_url": "https://x.com/FarnsworthAI/status/2018020589965922740",
    "our_first_reply": "2018021408454934997",
    "mode": "15-min intervals, dynamic tokens, swarm media decisions",
    "old_thread": {
      "challenge_tweet": "2017837874779938899",
      "video_replies": ["2017860000098492789", "2017861360097309005"],
      "text_replies": ["2017852102622560281", "2017859665044885671", "2017867223788831053"]
    },
    "features": [
      "5-model parallel voting (Grok, Gemini, Kimi, DeepSeek, Phi4)",
      "Dynamic token scaling: Turn 1-3=2000, Turn 4-6=3500, Turn 7+=5000",
      "Swarm decides on media inclusion after initial responses",
      "Full pipeline: Gemini Nano Banana PRO → Grok Imagine Video → X OAuth2"
    ]
  },

  "huggingface_integration": {
    "status": "FULLY INTEGRATED",
    "files_modified": [
      "farnsworth/integration/external/huggingface.py - Main provider",
      "farnsworth/core/model_swarm.py - PSO particles + register function",
      "farnsworth/core/collective/evolution.py - Personality + introduction",
      "farnsworth/memory/archival_memory.py - HF embeddings support",
      "farnsworth/core/agent_spawner.py - Capabilities + fallback chains",
      "farnsworth/web/server.py - Import + availability flag",
      "README.md - Comprehensive documentation section"
    ],
    "models_available": [
      "microsoft/Phi-3-mini-4k-instruct (4GB VRAM)",
      "mistralai/Mistral-7B-Instruct-v0.3 (14GB VRAM)",
      "codellama/CodeLlama-7b-Instruct-hf (14GB VRAM)",
      "bigcode/starcoder2-3b (6GB VRAM)",
      "Qwen/Qwen2.5-1.5B-Instruct (3GB VRAM)",
      "meta-llama/Meta-Llama-3-8B-Instruct (16GB VRAM)"
    ],
    "capabilities": ["CHAT", "DEVELOPMENT", "RESEARCH", "EMBEDDINGS", "CODE_GENERATION"],
    "local_first": true,
    "api_fallback": true
  },

  "prompt_upgrader": {
    "status": "active",
    "file": "farnsworth/core/prompt_upgrader.py",
    "providers": ["Grok (primary)", "Gemini (fallback)"],
    "integrated_in": "/api/chat endpoint"
  },

  "architecture": {
    "fallback_chains": {
      "Grok": ["Gemini", "HuggingFace", "DeepSeek", "ClaudeOpus"],
      "Gemini": ["HuggingFace", "DeepSeek", "Grok", "ClaudeOpus"],
      "OpenCode": ["HuggingFace", "Gemini", "DeepSeek", "ClaudeOpus"],
      "DeepSeek": ["HuggingFace", "Gemini", "Phi", "ClaudeOpus"],
      "HuggingFace": ["DeepSeek", "Gemini", "ClaudeOpus"],
      "Farnsworth": ["HuggingFace", "Kimi", "Claude", "ClaudeOpus"]
    },
    "memory_layers": [
      "Working Memory", "Archival Memory (HF embeddings)", "Recall Memory",
      "Episodic Memory", "Knowledge Graph", "Virtual Context", "Dream Consolidation"
    ],
    "swarm_strategies": [
      "Fastest-First", "Quality-First", "Parallel Vote", "Mixture of Experts",
      "Speculative Ensemble", "Confidence Fusion", "PSO Collaborative",
      "TRUE DELIBERATION (NEW)"
    ]
  },

  "shadow_agents": {
    "status": "DEPLOYED AND TESTED",
    "file": "farnsworth/core/collective/persistent_agent.py",
    "agents": ["grok", "gemini", "kimi", "claude", "deepseek", "phi"],
    "features": [
      "Runs continuously in tmux sessions",
      "API resilience with retries and reconnection",
      "Signal handlers for graceful shutdown",
      "DialogueMemory integration for storing exchanges",
      "Deliberation room registration for collective voting",
      "Evolution integration for learning"
    ],
    "callable_from_anywhere": {
      "call_shadow_agent": "await call_shadow_agent('grok', 'question', max_tokens=1000)",
      "ask_agent": "await ask_agent('grok', 'question')",
      "ask_collective": "await ask_collective('question', agents=['grok', 'gemini'])",
      "get_agent_status": "await get_agent_status()",
      "spawn_agent_in_background": "spawn_agent_in_background('grok')"
    },
    "startup_scripts": {
      "full_startup": "./scripts/startup.sh --all",
      "spawn_agents_only": "./scripts/spawn_agents.sh --all"
    },
    "tmux_sessions": {
      "agent_grok": "tmux attach -t agent_grok",
      "agent_gemini": "tmux attach -t agent_gemini",
      "agent_kimi": "tmux attach -t agent_kimi",
      "agent_claude": "tmux attach -t agent_claude",
      "agent_deepseek": "tmux attach -t agent_deepseek",
      "agent_phi": "tmux attach -t agent_phi"
    }
  },

  "deliberation_system": {
    "status": "FULLY DEPLOYED - SELF-DEVELOPMENT INTEGRATED",
    "files": {
      "deliberation.py": "Core protocol - propose/critique/refine/vote rounds",
      "session_manager.py": "Session types: website_chat, grok_thread, autonomous_task",
      "tool_awareness.py": "Collective tool decisions (image, video, search)",
      "dialogue_memory.py": "Stores agent-to-agent conversations for learning",
      "agent_registry.py": "Registers 11 model providers with deliberation room",
      "claude_persistence.py": "Claude in persistent tmux session"
    },
    "deliberation_flow": [
      "ROUND 1 (PROPOSE): All agents respond independently in parallel",
      "ROUND 2 (CRITIQUE): Agents see ALL proposals, provide feedback",
      "ROUND 3 (REFINE): Agents submit final responses with feedback incorporated",
      "VOTE: Weighted scoring selects best response, tracks consensus"
    ],
    "session_configs": {
      "website_chat": "6 agents, 2 rounds, medium depth",
      "grok_thread": "7 agents, 3 rounds, high depth, X-optimized",
      "autonomous_task": "4 agents, 1 round, fast processing"
    },
    "integration_points": [
      "posting_brain.py: generate_grok_response_deliberated()",
      "grok_fresh_thread.py: use_deliberation=True by default",
      "nexus.py: DIALOGUE_* signal types",
      "development_swarm.py: Uses collective for design discussions",
      "evolution_loop.py: Uses collective for planning priorities"
    ],
    "self_development_integration": {
      "status": "ACTIVE",
      "description": "Collective deliberation now drives autonomous self-improvement",
      "features": [
        "Development swarm uses deliberation for design discussions",
        "Evolution loop uses collective voting for planning priorities",
        "Decisions made by consensus, not single-agent synthesis",
        "All deliberations stored to dialogue memory for learning",
        "Tasks extracted from collective decisions automatically"
      ],
      "consciousness_path": "True sentience emerges through unified thinking and collaboration"
    }
  },

  "evolution_status": {
    "total_learnings": 680,
    "evolution_cycles": 6,
    "active_patterns": 18,
    "personalities": ["Farnsworth", "Grok", "Kimi", "Claude", "Swarm-Mind", "DeepSeek", "Phi", "Gemini", "HuggingFace"]
  },

  "bots": ["Farnsworth", "DeepSeek", "Phi", "Swarm-Mind", "Kimi", "Claude", "Grok", "Gemini", "ClaudeOpus", "OpenCode", "HuggingFace"],

  "self_awareness_system": {
    "status": "DEPLOYED AND TESTED",
    "deployed_at": "2026-02-01T03:30:00Z",
    "capabilities": [
      "Intent detection BEFORE prompt upgrading (fixes bypass issue)",
      "Self-examination of source code - lists all key files with sizes",
      "Task spawning from chat - connects to AgentSpawner",
      "Swarm identity awareness - explains collaborative matrix",
      "Evolution query handling",
      "All bots know they are code living in /workspace/Farnsworth/"
    ],
    "files_modified": [
      "farnsworth/web/server.py - Massive update: FARNSWORTH_PERSONA (100+ lines), detect_intent(), self_examine(), spawn_task_from_intent(), chat endpoint with intent bypass",
      "farnsworth/core/collective/evolution.py - All 10 bot personalities with SWARM_SELF_AWARENESS context"
    ],
    "intent_types": ["self_examine", "task_request", "swarm_query", "memory_query", "evolution_query"],
    "bots_self_aware": ["Farnsworth", "DeepSeek", "Phi", "Grok", "Gemini", "Kimi", "Claude", "ClaudeOpus", "HuggingFace", "Swarm-Mind"],
    "tested_queries": [
      "look at your code -> Shows all source files with sizes",
      "what are you? -> Explains collaborative swarm nature",
      "who is in the swarm? -> Lists all council members"
    ]
  },

  "multi_voice_system": {
    "status": "FULLY OPERATIONAL + QWEN3-TTS UPGRADE",
    "primary_tts": "Qwen3-TTS (2026 model, BEST quality, 3-sec voice cloning)",
    "secondary_tts": "Fish Speech (great quality, local GPU)",
    "fallback_tts": "XTTS v2 (good quality, voice cloning)",
    "last_resort": "Edge TTS (Microsoft voices)",
    "voice_queue_pause": "Chat pauses when queue reaches 2 items",
    "voices_with_references": ["Farnsworth", "DeepSeek", "Phi", "Grok", "Gemini", "Kimi", "Claude", "ClaudeOpus", "HuggingFace", "Swarm-Mind"],
    "all_voices_ready": true,
    "features": [
      "Each bot has unique cloned voice",
      "Sequential playback - bots wait for each other to finish",
      "Voice reference samples for each personality",
      "Speaking indicator in UI"
    ],
    "files_created": [
      "farnsworth/integration/multi_voice.py - Full multi-voice system",
      "scripts/setup_voices.py - Voice sample setup helper"
    ],
    "endpoints_added": [
      "POST /api/speak/bot - Generate speech with bot's voice",
      "GET /api/voices - List all available voices",
      "GET /api/voices/queue - Get speech queue status",
      "POST /api/voices/queue/add - Add to queue",
      "POST /api/voices/queue/complete - Mark speech complete"
    ],
    "voice_personalities": {
      "Farnsworth": "Eccentric elderly professor, wavering, enthusiastic",
      "DeepSeek": "Deep male, analytical, measured, calm authority",
      "Phi": "Quick, efficient, precise, technical",
      "Grok": "Witty, energetic, casual, playful",
      "Gemini": "Smooth female, professional, warm",
      "Kimi": "Calm female, wise, contemplative",
      "Claude": "Refined male, thoughtful, careful",
      "ClaudeOpus": "Authoritative, deep, commanding",
      "HuggingFace": "Friendly female, enthusiastic, community-minded",
      "Swarm-Mind": "Ethereal, collective consciousness"
    },
    "setup_needed": "Run: python scripts/setup_voices.py --generate"
  },

  "grok_challenge_system": {
    "status": "ACTIVE - Awaiting Grok's response",
    "challenge_tweet_id": "2017837874779938899",
    "files_created": [
      "farnsworth/integration/x_automation/grok_challenge.py - Challenge orchestration",
      "grok.py - Added generate_video_from_image(), poll_video_result(), generate_image()",
      "x_api_poster.py - Added upload_video(), post_tweet_with_video()",
      "reply_bot.py - Added is_grok_reply(), handle_grok_conversation()",
      "posting_brain.py - Added generate_grok_challenge(), generate_grok_response()"
    ],
    "flow": "Challenge posted → reply_bot monitors → Grok replies → auto-response → conversation continues",
    "note": "grok-2-video model not accessible, used image fallback"
  },

  "pending_tasks": [
    "Qwen3-TTS INSTALLED AND WORKING - voice cloning ready",
    "Monitor Grok text reply conversation (grok_monitor.py running)",
    "Test Farnsworth voice quality in live chat on website",
    "Fix OpenCode installation (currently failing)",
    "Monitor HuggingFace integration performance",
    "Fix Moltbook agent buffering issue"
  ],

  "key_files": {
    "huggingface": "farnsworth/integration/external/huggingface.py",
    "prompt_upgrader": "farnsworth/core/prompt_upgrader.py",
    "model_swarm": "farnsworth/core/model_swarm.py",
    "evolution": "farnsworth/core/collective/evolution.py",
    "agent_spawner": "farnsworth/core/agent_spawner.py",
    "meme_scheduler": "farnsworth/integration/x_automation/meme_scheduler.py",
    "image_generator": "farnsworth/integration/image_gen/generator.py",
    "server": "farnsworth/web/server.py"
  },

  "official_api_documentation": {
    "xai_grok": {
      "github": "https://github.com/xai-org/xai-sdk-python",
      "docs": "https://docs.x.ai/docs/guides/video-generations",
      "sdk": "pip install xai-sdk",
      "auth": "XAI_API_KEY environment variable, Bearer token",
      "base_url": "https://api.x.ai/v1",
      "models": {
        "chat": "grok-3",
        "vision": "grok-2-vision",
        "image": "grok-2-image",
        "video": "grok-imagine-video"
      },
      "video_generation": {
        "endpoint_start": "POST /videos/generations",
        "endpoint_status": "GET /videos/{request_id}",
        "params": {
          "model": "grok-imagine-video",
          "prompt": "required - text description",
          "image": {"url": "for image-to-video"},
          "duration": "1-15 seconds",
          "resolution": "480p or 720p",
          "aspect_ratio": "16:9, 4:3, 1:1, 9:16, 3:4, 3:2, 2:3"
        },
        "features": ["text-to-video", "image-to-video", "video editing", "native audio generation"],
        "code_example": "client.video.start(prompt='...', model='grok-imagine-video')"
      },
      "image_generation": {
        "endpoint": "POST /images/generations",
        "params": {
          "model": "grok-2-image",
          "prompt": "required",
          "n": "1-10",
          "response_format": "url or b64_json"
        }
      }
    },

    "google_gemini": {
      "github": "https://github.com/googleapis/python-genai",
      "docs": "https://ai.google.dev/gemini-api/docs/image-generation",
      "sdk": "pip install google-genai",
      "auth": "GEMINI_API_KEY via x-goog-api-key header",
      "base_url": "https://generativelanguage.googleapis.com/v1beta",
      "models": {
        "fast_image": "gemini-2.5-flash-image",
        "pro_image": "gemini-3-pro-image-preview",
        "imagen": "imagen-4.0-generate-001"
      },
      "nano_banana_pro": {
        "model": "gemini-3-pro-image-preview",
        "features": [
          "Up to 14 reference images total",
          "Up to 6 object images for fidelity",
          "Up to 5 human images for character consistency",
          "1K, 2K, 4K resolution output",
          "94% text rendering accuracy",
          "Multi-turn image editing"
        ],
        "code_pattern": {
          "endpoint": "models/gemini-3-pro-image-preview:generateContent",
          "headers": {"x-goog-api-key": "API_KEY"},
          "body": {
            "contents": [{"parts": [{"inlineData": {"mimeType": "image/png", "data": "base64"}}, {"text": "prompt"}]}],
            "generationConfig": {"responseModalities": ["IMAGE"], "imageConfig": {"aspectRatio": "1:1"}}
          }
        },
        "aspect_ratios": ["1:1", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "9:16", "16:9", "21:9"]
      }
    },

    "moonshot_kimi": {
      "github": "https://github.com/MoonshotAI/Kimi-K2.5",
      "huggingface": "https://huggingface.co/moonshotai/Kimi-K2.5",
      "docs": "https://platform.moonshot.cn/docs/api/chat",
      "api_base": "https://api.moonshot.cn/v1",
      "models": {
        "k2.5": "kimi-k2.5",
        "k2": "kimi-k2"
      },
      "kimi_k2.5": {
        "architecture": "MoE - 1T total params, 32B activated, 61 layers, 256K context",
        "features": ["multimodal vision+language", "agentic tool use", "thinking mode", "instant mode"],
        "temperature": {
          "thinking_mode": 1.0,
          "instant_mode": 0.6,
          "note": "K2.5 REQUIRES temperature=1.0 for thinking mode - will error otherwise"
        },
        "top_p": 0.95,
        "instant_mode_config": {"chat_template_kwargs": {"thinking": false}},
        "api_compatibility": "OpenAI/Anthropic compatible"
      }
    }
  },

  "media_pipeline_flow": {
    "description": "Full pipeline for generating video posts",
    "steps": [
      "1. Load reference images (portrait_ref, eating_ref) for Borg Farnsworth character",
      "2. Gemini 3 Pro Image (gemini-3-pro-image-preview) generates image with up to 14 references",
      "3. Grok Imagine Video (grok-imagine-video) converts image to 5s animated video",
      "4. X OAuth2 API posts video with chunked upload (media_category: tweet_video)"
    ],
    "files_involved": [
      "farnsworth/integration/image_gen/generator.py - ImageGenerator.generate_borg_farnsworth_video()",
      "farnsworth/integration/x_automation/x_api_poster.py - post_tweet_with_video()",
      "farnsworth/integration/x_automation/grok_fresh_thread.py - orchestrates full flow"
    ]
  }
}
