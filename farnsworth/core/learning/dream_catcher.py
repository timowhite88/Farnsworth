"""
Farnsworth Dream Catcher (Offline Consolidation)
------------------------------------------------

"I'll be in the Angry Dome! ...Learning!"

This innovative module runs when the system is idle. It performs "Offline Memory Consolidation":
1.  **Synthetic Replay**: Takes recent memories (vector store entries) and uses a small local LLM
    to generate hypothetical questions that *would have* retrieved those memories.
2.  **Dataset Generation**: Creates a `(Instruction, Input, Output)` JSONL pair.
3.  **Self-Correction**: Critiques its own past responses to create "Gold Standard" training data.
4.  **Hypnopedia**: (Optional) Fine-tunes a local LoRA adapter on this data.

Impact: The system actually gets smarter *overnight* based on what you worked on today.
"""

import asyncio
import json
import random
from typing import List, Dict
from datetime import datetime
from loguru import logger

class DreamCatcher:
    def __init__(self, output_dir: str = "./data/dreams"):
        self.output_dir = output_dir
        self.dream_log = []
        
    async def enter_rem_sleep(self, recent_memories: List[str]):
        """
        The core loop. Takes raw memories and 'dreams' up synthetic training examples.
        """
        logger.info("ðŸ’¤ Entering REM Sleep (Memory Consolidation)...")
        dreams = []
        
        for memory in recent_memories:
            # 1. Hallucinate a User Query (Reverse-Engineering)
            # In prod, this calls a local LLM or the Swarm
            synthetic_query = self._hallucinate_query(memory)
            
            # 2. Refine the Response
            # We assume the memory snippet is the 'Ground Truth' fact
            refined_answer = self._synthesize_answer(synthetic_query, memory)
            
            dream_entry = {
                "instruction": synthetic_query,
                "input": "",
                "output": refined_answer,
                "dream_timestamp": datetime.now().isoformat(),
                "source_memory_hash": str(hash(memory))
            }
            dreams.append(dream_entry)
            logger.debug(f"Dreamt: {synthetic_query[:30]}...")
            
        # 3. Consolidate (Save to disk for LoRA training)
        self._save_dreams(dreams)
        logger.info(f"âœ¨ Woke up! Consolidated {len(dreams)} new insights.")
        return dreams

    def _hallucinate_query(self, memory_content: str) -> str:
        """
        Mock LLM call: Given an answer, guess the question.
        """
        # Heuristic for demo
        words = memory_content.split()
        topic = words[0] if words else "this topic"
        templates = [
            f"How does {topic} actually work?",
            f"Explain the significance of {topic}.",
            f"What did we discuss regarding {topic}?",
            f"Summarize the key points about {topic}."
        ]
        return random.choice(templates)

    def _synthesize_answer(self, query: str, context: str) -> str:
        """
        Synthesizes a clean, high-quality answer using the context.
        """
        return f"Based on our records: {context}"

    def _save_dreams(self, dreams: List[Dict]):
        """Append to JSONL dataset."""
        import os
        os.makedirs(self.output_dir, exist_ok=True)
        file_path = f"{self.output_dir}/dream_journal.jsonl"
        
        with open(file_path, "a", encoding='utf-8') as f:
            for dream in dreams:
                f.write(json.dumps(dream) + "\n")

# Integration Hook
async def demo_dream_mode():
    dc = DreamCatcher()
    # Simulate some raw memories from the day
    daily_residue = [
        "The Docker container fails with exit code 137 because of OOM killer.",
        "Professor Farnsworth's favorite color is Quantum Grey.",
        "The secret API key for Helius is hidden in the .env.example file."
    ]
    
    await dc.enter_rem_sleep(daily_residue)

if __name__ == "__main__":
    asyncio.run(demo_dream_mode())
