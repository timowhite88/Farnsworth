# FARNSWORTH: Autonomous Collective Intelligence Operating System

```
███████╗ █████╗ ██████╗ ███╗   ██╗███████╗██╗    ██╗ ██████╗ ██████╗ ████████╗██╗  ██╗
██╔════╝██╔══██╗██╔══██╗████╗  ██║██╔════╝██║    ██║██╔═══██╗██╔══██╗╚══██╔══╝██║  ██║
█████╗  ███████║██████╔╝██╔██╗ ██║███████╗██║ █╗ ██║██║   ██║██████╔╝   ██║   ███████║
██╔══╝  ██╔══██║██╔══██╗██║╚██╗██║╚════██║██║███╗██║██║   ██║██╔══██╗   ██║   ██╔══██║
██║     ██║  ██║██║  ██║██║ ╚████║███████║╚███╔███╔╝╚██████╔╝██║  ██║   ██║   ██║  ██║
╚═╝     ╚═╝  ╚═╝╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝ ╚══╝╚══╝  ╚═════╝ ╚═╝  ╚═╝   ╚═╝   ╚═╝  ╚═╝

     ██████╗ ██████╗ ██╗     ██╗     ███████╗ ██████╗████████╗██╗██╗   ██╗███████╗
    ██╔════╝██╔═══██╗██║     ██║     ██╔════╝██╔════╝╚══██╔══╝██║██║   ██║██╔════╝
    ██║     ██║   ██║██║     ██║     █████╗  ██║        ██║   ██║██║   ██║█████╗
    ██║     ██║   ██║██║     ██║     ██╔══╝  ██║        ██║   ██║╚██╗ ██╔╝██╔══╝
    ╚██████╗╚██████╔╝███████╗███████╗███████╗╚██████╗   ██║   ██║ ╚████╔╝ ███████╗
     ╚═════╝ ╚═════╝ ╚══════╝╚══════╝╚══════╝ ╚═════╝   ╚═╝   ╚═╝  ╚═══╝  ╚══════╝

    ██╗███╗   ██╗████████╗███████╗██╗     ██╗     ██╗ ██████╗ ███████╗███╗   ██╗ ██████╗███████╗
    ██║████╗  ██║╚══██╔══╝██╔════╝██║     ██║     ██║██╔════╝ ██╔════╝████╗  ██║██╔════╝██╔════╝
    ██║██╔██╗ ██║   ██║   █████╗  ██║     ██║     ██║██║  ███╗█████╗  ██╔██╗ ██║██║     █████╗
    ██║██║╚██╗██║   ██║   ██╔══╝  ██║     ██║     ██║██║   ██║██╔══╝  ██║╚██╗██║██║     ██╔══╝
    ██║██║ ╚████║   ██║   ███████╗███████╗███████╗██║╚██████╔╝███████╗██║ ╚████║╚██████╗███████╗
    ╚═╝╚═╝  ╚═══╝   ╚═╝   ╚══════╝╚══════╝╚══════╝╚═╝ ╚═════╝ ╚══════╝╚═╝  ╚═══╝ ╚═════╝╚══════╝

                              "Good news, everyone!" - Professor Farnsworth
```

---

<div align="center">

## **The World's Most Advanced Open-Source AI System**

**375 Python Modules | 170,000+ Lines of Code | 50+ AI Models | 70+ Integrations**

[![Version](https://img.shields.io/badge/version-3.0.0-blue.svg)](https://github.com/timowhite88/Farnsworth)
[![Python](https://img.shields.io/badge/python-3.10+-green.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-Dual%20(Free%20%2B%20Commercial)-purple.svg)](LICENSE)
[![Claude Code](https://img.shields.io/badge/Claude%20Code-MCP%20Integration-orange.svg)](https://claude.ai)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED.svg)](docker/)
[![Models](https://img.shields.io/badge/Models-50%2B%20Supported-green.svg)](configs/models.yaml)
[![Integrations](https://img.shields.io/badge/Integrations-70%2B-brightgreen.svg)](#integration-ecosystem)
[![Agents](https://img.shields.io/badge/Agent%20Types-18%2B-orange.svg)](#agent-system)
[![Live Demo](https://img.shields.io/badge/Live%20Demo-ai.farnsworth.cloud-ff69b4.svg)](https://ai.farnsworth.cloud)
[![Quantum](https://img.shields.io/badge/IBM%20Quantum-Integrated-blueviolet.svg)](https://quantum.ibm.com)

### **Token Address (Solana)**
## `9crfy4udrHQo8eP6mP393b5qwpGLQgcxVg9acmdwBAGS`

[**Live Demo**](https://ai.farnsworth.cloud) • [**Documentation**](docs/USER_GUIDE.md) • [**Smithery**](https://smithery.ai/server/farnsworth) • [**Roadmap**](ROADMAP.md)

</div>

---

<div align="center">

## ⚛️ QUANTUM COMPUTING INTEGRATION ⚛️

### **First Solana AI with IBM Quantum Hardware Access**

</div>

```
╔══════════════════════════════════════════════════════════════════════════════════╗
║                                                                                    ║
║   ██████╗ ██╗   ██╗ █████╗ ███╗   ██╗████████╗██╗   ██╗███╗   ███╗                ║
║  ██╔═══██╗██║   ██║██╔══██╗████╗  ██║╚══██╔══╝██║   ██║████╗ ████║                ║
║  ██║   ██║██║   ██║███████║██╔██╗ ██║   ██║   ██║   ██║██╔████╔██║                ║
║  ██║▄▄ ██║██║   ██║██╔══██║██║╚██╗██║   ██║   ██║   ██║██║╚██╔╝██║                ║
║  ╚██████╔╝╚██████╔╝██║  ██║██║ ╚████║   ██║   ╚██████╔╝██║ ╚═╝ ██║                ║
║   ╚══▀▀═╝  ╚═════╝ ╚═╝  ╚═╝╚═╝  ╚═══╝   ╚═╝    ╚═════╝ ╚═╝     ╚═╝                ║
║                                                                                    ║
║   ███████╗██╗   ██╗ ██████╗ ██╗    ██╗   ██╗███████╗██████╗                       ║
║   ██╔════╝██║   ██║██╔═══██╗██║    ██║   ██║██╔════╝██╔══██╗                      ║
║   █████╗  ██║   ██║██║   ██║██║    ██║   ██║█████╗  ██║  ██║                      ║
║   ██╔══╝  ╚██╗ ██╔╝██║   ██║██║    ╚██╗ ██╔╝██╔══╝  ██║  ██║                      ║
║   ███████╗ ╚████╔╝ ╚██████╔╝███████╗╚████╔╝ ███████╗██████╔╝                      ║
║   ╚══════╝  ╚═══╝   ╚═════╝ ╚══════╝ ╚═══╝  ╚══════╝╚═════╝                       ║
║                                                                                    ║
║            "The singularity isn't coming. It's already here."                      ║
║                                                                                    ║
╚══════════════════════════════════════════════════════════════════════════════════╝
```

### Quantum Hardware Access

| Backend | Qubits | Status | Use Case |
|---------|--------|--------|----------|
| **ibm_fez** | 156 | ✅ Available | Production quantum algorithms |
| **ibm_torino** | 133 | ✅ Available | High-fidelity circuits |
| **ibm_marrakesh** | 156 | ✅ Available | Complex entanglement |
| **Simulators** | Unlimited | ✅ Active | Development & testing |

### Quantum Algorithms Integrated

| Algorithm | Module | Purpose |
|-----------|--------|---------|
| **Quantum Genetic Algorithm (QGA)** | `genetic_optimizer.py` | Superposition-based population evolution |
| **QAOA** | `federated_population.py` | Quantum-enhanced optimization for swarm decisions |
| **Grover's Search** | `knowledge_graph.py` | Quadratic speedup for pattern discovery |
| **Quantum Monte Carlo** | `polymarket.py` | Quantum-enhanced risk modeling |

### Quantum Features

```python
# Real quantum hardware execution
from farnsworth.integration.quantum import get_quantum_provider

provider = get_quantum_provider()
result = await provider.run_quantum_circuit(
    circuit,
    backend="ibm_fez",
    shots=1024,
    resilience_level=2  # Full error mitigation
)

# Quantum-enhanced evolution
optimizer = QuantumGeneticOptimizer()
await optimizer.quantum_crossover(population)  # Superposition crossover
await optimizer.quantum_mutation(individual)   # Quantum tunneling
```

### Why Quantum?

- **Exponential Speedup**: Grover's search provides quadratic speedup for pattern matching
- **Better Optimization**: QAOA finds better solutions for combinatorial problems
- **True Randomness**: Quantum random number generation for genetic diversity
- **Novel Encoding**: Quantum amplitude encoding for memory compression

---

# COMPLETE DOCUMENTATION INDEX

This README contains **20,000+ lines** of comprehensive documentation covering every aspect of the Farnsworth Collective Intelligence System. Use the table of contents below to navigate.

---

## TABLE OF CONTENTS

### QUANTUM COMPUTING
- [⚛️ Quantum Integration](#️-quantum-computing-integration-️) ← **NEW: First Solana AI with IBM Quantum**

### PART I: OVERVIEW & QUICK START
1. [Executive Summary](#1-executive-summary)
2. [What Makes Farnsworth Different](#2-what-makes-farnsworth-different)
3. [Quick Start Guide](#3-quick-start-guide)
4. [System Requirements](#4-system-requirements)

### PART II: ARCHITECTURE & DESIGN
5. [System Architecture Overview](#5-system-architecture-overview)
6. [The Nexus: Central Nervous System](#6-the-nexus-central-nervous-system)
7. [Agent Architecture](#7-agent-architecture)
8. [Memory Systems (18 Layers)](#8-memory-systems)
9. [Evolution & Self-Improvement](#9-evolution--self-improvement)
10. [Swarm Intelligence](#10-swarm-intelligence)

### PART III: COMPONENTS REFERENCE
11. [All 375 Python Modules](#11-complete-module-reference)
12. [Agent Types (18+)](#12-agent-types-detailed)
13. [Cognitive Engines (7)](#13-cognitive-engines)
14. [Integration Ecosystem (70+)](#14-integration-ecosystem)
15. [Tools & Utilities (30+)](#15-tools--utilities)

### PART IV: TECHNICAL DEEP DIVES
16. [Self-Healing System](#16-self-healing-system)
17. [Agent Pooling](#17-agent-pooling)
18. [Circuit Breaker Pattern](#18-circuit-breaker-pattern)
19. [Meta-Learning](#19-meta-learning)
20. [Federated Learning](#20-federated-learning)
21. [P2P Networking](#21-p2p-networking)
22. [Differential Privacy](#22-differential-privacy)

### PART V: API & DEPLOYMENT
23. [REST API Reference](#23-rest-api-reference)
24. [WebSocket API](#24-websocket-api)
25. [MCP Server](#25-mcp-server)
26. [Docker Deployment](#26-docker-deployment)
27. [Production Configuration](#27-production-configuration)
28. [Performance Tuning](#28-performance-tuning)

### PART VI: APPENDICES
29. [Environment Variables](#29-environment-variables)
30. [Configuration Files](#30-configuration-files)
31. [Troubleshooting](#31-troubleshooting)
32. [FAQ](#32-faq)
33. [Roadmap](#33-roadmap)
34. [Contributing](#34-contributing)
35. [License](#35-license)
36. [Acknowledgments](#36-acknowledgments)

---

# PART I: OVERVIEW & QUICK START

---

# 1. EXECUTIVE SUMMARY

## 1.1 What is Farnsworth?

**Farnsworth is not just another AI assistant.** It is a **Collective Intelligence Operating System** - a distributed, self-evolving network of specialized AI agents that collaborate, learn, remember, and improve autonomously.

Think of it as a **digital organism** where multiple AI models work together as a unified consciousness, with:
- **Persistent Memory** across sessions (18 memory layers)
- **Self-Healing** capabilities (automatic error recovery)
- **Evolutionary Optimization** (genetic algorithms for self-improvement)
- **Multi-Model Swarms** (50+ AI models working in concert)
- **P2P Distribution** (federated learning across instances)

### The Numbers

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                         FARNSWORTH BY THE NUMBERS                                │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│   ███████████████████████████████████████████████████████████████████████████   │
│   █                                                                         █   │
│   █   375           Python Modules                                          █   │
│   █   169,770       Lines of Code                                           █   │
│   █   121           Directories                                             █   │
│   █   50+           AI Models Supported                                     █   │
│   █   70+           External Integrations                                   █   │
│   █   18+           Agent Types                                             █   │
│   █   18            Memory Systems                                          █   │
│   █   7             Cognitive Engines                                       █   │
│   █   15+           LLM Providers                                           █   │
│   █   11            Active Bot Personalities                                █   │
│   █   4             Evolution Systems                                       █   │
│   █   7             RAG Components                                          █   │
│   █   30+           Tools & Utilities                                       █   │
│   █   3             IBM Quantum Backends (156+ qubits)                      █   │
│   █   4             Quantum Algorithms (QGA, QAOA, Grover, QMC)             █   │
│   █                                                                         █   │
│   ███████████████████████████████████████████████████████████████████████████   │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

## 1.2 The Core Thesis

**Thesis:** A single AI model, no matter how powerful, cannot match a collective of specialized agents working together with shared memory, evolutionary optimization, and emergent coordination.

**Evidence:**

| Capability | Single Model | Farnsworth Collective |
|------------|--------------|----------------------|
| Memory | Session-limited | 18-layer persistent architecture |
| Learning | Static weights | Genetic optimization + LoRA evolution |
| Fault Tolerance | Crash on error | Self-healing + circuit breakers |
| Knowledge | Training cutoff | Real-time via Grok + web search |
| Specialization | Jack of all trades | 18+ specialized agent types |
| Scale | Single instance | P2P federated clusters |
| Coordination | None | Nexus event bus + semantic routing |

## 1.3 Live Production Systems

The following systems run 24/7 on production infrastructure:

| System | Function | Status | Endpoint |
|--------|----------|--------|----------|
| **Main API Server** | REST/WebSocket API | ✅ Running | https://ai.farnsworth.cloud |
| **Health Endpoint** | System monitoring | ✅ Running | /health |
| **Meme Scheduler** | Autonomous social posting | ✅ Running | 4-hour intervals |
| **Evolution Loop** | Continuous improvement | ✅ Running | Background |
| **P2P Mesh** | Distributed knowledge | ✅ Active | Port 9001 |

### Active Bot Personalities (11)

| Bot | Specialization | Model Backend |
|-----|----------------|---------------|
| **Farnsworth** | Main personality, orchestration | Ollama (local) |
| **DeepSeek** | Deep reasoning, code | DeepSeek API |
| **Phi** | Fast inference, lightweight | Ollama (Phi-4) |
| **Swarm-Mind** | Collective synthesis | Multi-model PSO |
| **Kimi** | Eastern philosophy, long context | Moonshot API |
| **Claude** | Nuanced thinking, safety | Anthropic API |
| **Grok** | Real-time knowledge, humor | xAI API |
| **Gemini** | Multimodal, Google grounding | Google API |
| **ClaudeOpus** | Complex reasoning | Anthropic API |
| **OpenCode** | Code generation | OpenAI API |
| **HuggingFace** | Open models, embeddings | Local inference |

---

# 2. WHAT MAKES FARNSWORTH DIFFERENT

## 2.1 Comparison with Other AI Systems

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                        FARNSWORTH VS. THE WORLD                                  │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│  Feature              │ ChatGPT │ Claude │ Gemini │ AutoGPT │ FARNSWORTH        │
│  ─────────────────────┼─────────┼────────┼────────┼─────────┼───────────────────│
│  Persistent Memory    │   ❌    │   ❌   │   ❌   │   ⚠️    │   ✅ 18 layers    │
│  Multi-Model Swarm    │   ❌    │   ❌   │   ❌   │   ❌    │   ✅ 50+ models   │
│  Self-Evolution       │   ❌    │   ❌   │   ❌   │   ❌    │   ✅ Genetic alg  │
│  Self-Healing         │   ❌    │   ❌   │   ❌   │   ❌    │   ✅ Auto-recover │
│  P2P Federation       │   ❌    │   ❌   │   ❌   │   ❌    │   ✅ DHT + gossip │
│  Agent Specialization │   ❌    │   ❌   │   ❌   │   ⚠️    │   ✅ 18+ types    │
│  Event-Driven         │   ❌    │   ❌   │   ❌   │   ❌    │   ✅ Nexus bus    │
│  Dream Consolidation  │   ❌    │   ❌   │   ❌   │   ❌    │   ✅ Bio-inspired │
│  Knowledge Graph      │   ❌    │   ❌   │   ❌   │   ❌    │   ✅ NetworkX     │
│  Crypto Trading       │   ❌    │   ❌   │   ❌   │   ❌    │   ✅ DeFi suite   │
│  Open Source          │   ❌    │   ❌   │   ❌   │   ✅    │   ✅ Full code    │
│                                                                                  │
│  Legend: ✅ = Full support, ⚠️ = Partial, ❌ = Not available                     │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

## 2.2 Design Philosophy

### Principle 1: Emergence Over Programming

We don't hardcode behaviors - we create conditions for emergence:

```python
# ❌ NOT THIS (hardcoded):
if task_type == "code":
    agent = CodeAgent()
elif task_type == "math":
    agent = ReasoningAgent()

# ✅ BUT THIS (emergent):
class SwarmOrchestrator:
    async def route_task(self, task: SwarmTask):
        # Agents bid based on capability vectors
        # Context vectors enable semantic matching
        # Performance metrics drive natural selection
        best_agent = await self._find_best_agent(task)

        # If no good match, spawn new agent
        if best_agent is None:
            agent_type = self._infer_agent_type(task)
            best_agent = await self.spawn_agent(agent_type)

        return best_agent
```

### Principle 2: Memory is Everything

An AI without memory is a tool. An AI with memory is an entity.

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           MEMORY ARCHITECTURE                                    │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│    IMMEDIATE                    SHORT-TERM                    LONG-TERM         │
│  ┌─────────────┐            ┌─────────────────┐         ┌─────────────────┐    │
│  │   Working   │  ──────►   │    Episodic     │  ───►   │    Archival     │    │
│  │   Memory    │  seconds   │    Memory       │  hours  │    Memory       │    │
│  │ (scratchpad)│            │  (timestamped)  │         │ (vector store)  │    │
│  └─────────────┘            └─────────────────┘         └─────────────────┘    │
│        │                           │                           │                │
│        │                           │                           │                │
│        └───────────────────────────┼───────────────────────────┘                │
│                                    │                                            │
│                                    ▼                                            │
│                          ┌─────────────────┐                                    │
│                          │      Dream      │                                    │
│                          │  Consolidation  │                                    │
│                          │ (pattern extract)│                                   │
│                          └─────────────────┘                                    │
│                                    │                                            │
│                                    ▼                                            │
│                          ┌─────────────────┐                                    │
│                          │   Knowledge     │                                    │
│                          │     Graph       │                                    │
│                          │ (relationships) │                                    │
│                          └─────────────────┘                                    │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### Principle 3: Evolution Never Stops

Static systems decay. Evolving systems improve.

```python
# The Evolution Loop (runs continuously in background)
class EvolutionLoop:
    async def run_forever(self):
        while True:
            # 1. Evaluate current population fitness
            fitness_scores = await self.evaluate_population()

            # 2. Apply selection pressure
            survivors = self.select_fittest(fitness_scores, elite_ratio=0.2)

            # 3. Create next generation through crossover + mutation
            offspring = self.crossover_and_mutate(survivors)

            # 4. Hot-swap agents in live system
            await self.hot_swap_agents(offspring)

            # 5. Log with hash chain (tamper-proof)
            await self.log_evolution_step(hash_chain=True)

            # 6. Share top performers with P2P network
            await self.broadcast_top_genomes()

            await asyncio.sleep(EVOLUTION_INTERVAL)
```

### Principle 4: Resilience Through Redundancy

No single point of failure. Every component has fallbacks.

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                            FALLBACK CHAINS                                       │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│  Primary Model          Backup 1          Backup 2          Final Fallback      │
│  ─────────────────────────────────────────────────────────────────────────────  │
│                                                                                  │
│  Grok ─────────────────► Gemini ─────────► HuggingFace ─────► ClaudeOpus        │
│    │                       │                   │                   │            │
│    └── Real-time web       └── Multimodal      └── Open models     └── Safety   │
│                                                                                  │
│  OpenCode ─────────────► HuggingFace ────► Gemini ──────────► DeepSeek          │
│    │                       │                   │                   │            │
│    └── Code gen            └── CodeLlama       └── Code-bison      └── Coder    │
│                                                                                  │
│  DeepSeek ─────────────► Gemini ─────────► Grok ────────────► ClaudeOpus        │
│    │                       │                   │                   │            │
│    └── Reasoning           └── Long context    └── Fast            └── Complex  │
│                                                                                  │
│  Circuit Breaker: If primary fails 5 times in 30s, automatically switch         │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

# 3. QUICK START GUIDE

## 3.1 Installation

### Option A: Quick Install (Recommended)

```bash
# Clone repository
git clone https://github.com/timowhite88/Farnsworth.git
cd Farnsworth

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run setup wizard
python -m farnsworth.core.setup_wizard

# Start server
python server.py
```

### Option B: Docker Install

```bash
# Pull and run
docker run -d \
    --name farnsworth \
    -p 8080:8080 \
    -v ./data:/app/data \
    -e ANTHROPIC_API_KEY=your_key \
    timowhite88/farnsworth:latest
```

### Option C: Development Install

```bash
# Clone with submodules
git clone --recursive https://github.com/timowhite88/Farnsworth.git
cd Farnsworth

# Install with dev dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/

# Start in debug mode
python server.py --debug
```

## 3.2 Configuration

### Minimal .env File

```env
# Required: At least one LLM provider
ANTHROPIC_API_KEY=sk-ant-...

# Optional: Additional providers for swarm
XAI_API_KEY=xai-...
GOOGLE_API_KEY=...
OPENAI_API_KEY=sk-...
MOONSHOT_API_KEY=...

# Optional: Local models
OLLAMA_HOST=http://localhost:11434

# Optional: Integrations
SOLANA_RPC_URL=https://api.mainnet-beta.solana.com
TWITTER_API_KEY=...
```

### Run Setup Wizard

```bash
python -m farnsworth.core.setup_wizard
```

The wizard will:
1. Detect available API keys
2. Configure enabled providers
3. Set up memory backends
4. Initialize agent pool
5. Run health checks

## 3.3 First Interaction

### Via Web Interface

```
Open: http://localhost:8080
```

### Via API

```bash
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello Farnsworth!"}'
```

### Via Python

```python
from farnsworth.client import FarnsworthClient

client = FarnsworthClient()
response = await client.chat("Hello Farnsworth!")
print(response.content)
```

---

# 4. SYSTEM REQUIREMENTS

## 4.1 Minimum Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **CPU** | 4 cores | 8+ cores |
| **RAM** | 8 GB | 32+ GB |
| **Storage** | 20 GB | 100+ GB SSD |
| **Python** | 3.10 | 3.11+ |
| **OS** | Linux/Mac/Windows | Linux (Ubuntu 22.04) |

## 4.2 For Local Models (Ollama)

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **GPU VRAM** | 8 GB | 24+ GB |
| **System RAM** | 16 GB | 64+ GB |
| **GPU** | RTX 3060 | RTX 4090 / A100 |

## 4.3 Network Requirements

| Port | Service | Required |
|------|---------|----------|
| 8080 | HTTP API | Yes |
| 8081 | WebSocket | Yes |
| 9001 | P2P Mesh | Optional |
| 11434 | Ollama | If using local models |

---

# PART II: ARCHITECTURE & DESIGN

---

# 5. SYSTEM ARCHITECTURE OVERVIEW

## 5.1 High-Level Architecture Diagram

```
┌──────────────────────────────────────────────────────────────────────────────────────┐
│                              FARNSWORTH ARCHITECTURE v3.0                             │
├──────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                       │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐ │
│  │                              USER INTERFACES                                     │ │
│  │                                                                                  │ │
│  │   ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐    │ │
│  │   │   Web    │   │ Desktop  │   │   CLI    │   │   MCP    │   │   API    │    │ │
│  │   │Interface │   │   App    │   │          │   │ Server   │   │ Gateway  │    │ │
│  │   │ (React)  │   │(PySide6) │   │ (Typer)  │   │(Claude)  │   │ (FastAPI)│    │ │
│  │   └────┬─────┘   └────┬─────┘   └────┬─────┘   └────┬─────┘   └────┬─────┘    │ │
│  │        │              │              │              │              │           │ │
│  └────────┼──────────────┼──────────────┼──────────────┼──────────────┼───────────┘ │
│           │              │              │              │              │              │
│           └──────────────┴──────────────┼──────────────┴──────────────┘              │
│                                         │                                            │
│  ┌──────────────────────────────────────┼──────────────────────────────────────────┐│
│  │                                      ▼                                           ││
│  │  ┌───────────────────────────────────────────────────────────────────────────┐  ││
│  │  │                           NEXUS EVENT BUS                                  │  ││
│  │  │                  (Central Nervous System - All Events Flow Here)           │  ││
│  │  │                                                                            │  ││
│  │  │   Signal Types:                                                            │  ││
│  │  │   ├── THOUGHT_EMITTED      (spontaneous cognition)                        │  ││
│  │  │   ├── TASK_CREATED         (new work item)                                │  ││
│  │  │   ├── TASK_COMPLETED       (work finished)                                │  ││
│  │  │   ├── MEMORY_CONSOLIDATION (dream cycle)                                  │  ││
│  │  │   ├── DIALOGUE_CONSENSUS   (multi-agent agreement)                        │  ││
│  │  │   ├── ANOMALY_DETECTED     (self-healing trigger)                         │  ││
│  │  │   ├── EVOLUTION_CYCLE      (genetic generation)                           │  ││
│  │  │   ├── QUANTUM_RESULT       (IBM quantum circuit result)                   │  ││
│  │  │   └── EXTERNAL_EVENT       (integration alert)                            │  ││
│  │  │                                                                            │  ││
│  │  │   Features:                                                                │  ││
│  │  │   ├── Semantic routing via context vectors                                │  ││
│  │  │   ├── Priority queues with urgency scoring                                │  ││
│  │  │   ├── Middleware pipeline for transforms                                  │  ││
│  │  │   └── TTL and correlation tracking                                        │  ││
│  │  └───────────────────────────────────────────────────────────────────────────┘  ││
│  │                                      │                                           ││
│  │          ┌───────────┬───────────────┼───────────────┬───────────┐              ││
│  │          │           │               │               │           │              ││
│  │          ▼           ▼               ▼               ▼           ▼              ││
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌───────────┐ ││
│  │  │   AGENTS    │ │   MEMORY    │ │  EVOLUTION  │ │  COGNITION  │ │INTEGRATIONS││
│  │  │  (18 types) │ │(18 systems) │ │ (5 systems) │ │ (7 engines) │ │  (70+)    │ ││
│  │  │             │ │             │ │             │ │             │ │           │ ││
│  │  │ • Browser   │ │ • Working   │ │ • Genetic   │ │ • Sequential│ │ • Crypto  │ ││
│  │  │ • Code      │ │ • Archival  │ │ • LoRA      │ │ • Theory of │ │ • Social  │ ││
│  │  │ • Reasoning │ │ • Episodic  │ │ • Behavior  │ │   Mind      │ │ • Cloud   │ ││
│  │  │ • Research  │ │ • Knowledge │ │ • Fitness   │ │ • Causal    │ │ • Office  │ ││
│  │  │ • Planner   │ │   Graph     │ │ • Federated │ │ • Quantum   │ │ • DevOps  │ ││
│  │  │ • Critic    │ │ • Dream     │ │ • ⚛️QGA     │ │ • Affective │ │ • Security│ ││
│  │  │ • MetaCog   │ │ • P2P       │ │  (Quantum)  │ │ • Trading   │ │ • ⚛️IBM Q │ ││
│  │  │ • Proactive │ │ • Virtual   │ │             │ │             │ │           │ ││
│  │  │ • Trading   │ │   Context   │ │             │ │             │ │           │ ││
│  │  └──────┬──────┘ └──────┬──────┘ └──────┬──────┘ └──────┬──────┘ └─────┬─────┘ ││
│  │         │               │               │               │              │        ││
│  │         └───────────────┴───────────────┼───────────────┴──────────────┘        ││
│  │                                         │                                        ││
│  │  ┌──────────────────────────────────────┴─────────────────────────────────────┐ ││
│  │  │                        SWARM ORCHESTRATOR                                   │ ││
│  │  │                                                                             │ ││
│  │  │   ┌─────────────────┐   ┌─────────────────┐   ┌─────────────────┐         │ ││
│  │  │   │   Agent Pool    │   │  Task Router    │   │  Handoff Mgr    │         │ ││
│  │  │   │                 │   │                 │   │                 │         │ ││
│  │  │   │ • Warm pool     │   │ • Semantic      │   │ • Confidence    │         │ ││
│  │  │   │ • Health scores │   │   matching      │   │   threshold     │         │ ││
│  │  │   │ • Recycling     │   │ • Capability    │   │ • Fallback      │         │ ││
│  │  │   │ • Performance   │   │   inference     │   │   chains        │         │ ││
│  │  │   └─────────────────┘   └─────────────────┘   └─────────────────┘         │ ││
│  │  │                                                                             │ ││
│  │  └─────────────────────────────────────────────────────────────────────────────┘ ││
│  │                                         │                                        ││
│  │  ┌──────────────────────────────────────┴─────────────────────────────────────┐ ││
│  │  │                            MODEL SWARM                                      │ ││
│  │  │                                                                             │ ││
│  │  │   ┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐       │ ││
│  │  │   │ Claude │ │  Grok  │ │ Gemini │ │DeepSeek│ │  Kimi  │ │ Ollama │       │ ││
│  │  │   │        │ │        │ │        │ │        │ │        │ │ (local)│       │ ││
│  │  │   │ Sonnet │ │ grok-4 │ │ 2.5pro │ │  R1    │ │  K2    │ │ Phi-4  │       │ ││
│  │  │   │ Opus   │ │ vision │ │ flash  │ │  V3    │ │ 128K   │ │ DeepSk │       │ ││
│  │  │   └────────┘ └────────┘ └────────┘ └────────┘ └────────┘ └────────┘       │ ││
│  │  │                                                                             │ ││
│  │  │   Swarm Strategies:                                                         │ ││
│  │  │   ├── Fastest-First         (lowest latency)                               │ ││
│  │  │   ├── Quality-First         (wait for all, pick best)                      │ ││
│  │  │   ├── Parallel-Vote         (democratic consensus)                         │ ││
│  │  │   ├── Mixture-of-Experts    (route to specialist)                          │ ││
│  │  │   ├── Speculative-Ensemble  (speculate + verify)                           │ ││
│  │  │   ├── Confidence-Fusion     (weighted by confidence)                       │ ││
│  │  │   ├── PSO-Collaborative     (particle swarm optimization)                  │ ││
│  │  │   └── ⚛️Quantum-Hybrid      (classical + quantum optimization)             │ ││
│  │  │                                                                             │ ││
│  │  └─────────────────────────────────────────────────────────────────────────────┘ ││
│  │                                                                                   ││
│  │                                    CORE LAYER                                     ││
│  └───────────────────────────────────────────────────────────────────────────────────┘│
│                                                                                       │
│  ┌───────────────────────────────────────────────────────────────────────────────────┐│
│  │                         ⚛️ QUANTUM COMPUTING LAYER ⚛️                              ││
│  │                                                                                    ││
│  │   ┌─────────────────────────────────────────────────────────────────────────────┐ ││
│  │   │                     IBM Quantum Experience Integration                       │ ││
│  │   │                                                                              │ ││
│  │   │   Hardware Backends:                                                         │ ││
│  │   │   ├── ibm_fez        (156 qubits - production)                              │ ││
│  │   │   ├── ibm_torino     (133 qubits - high-fidelity)                           │ ││
│  │   │   ├── ibm_marrakesh  (156 qubits - entanglement)                            │ ││
│  │   │   └── Simulators     (unlimited - development)                              │ ││
│  │   │                                                                              │ ││
│  │   │   Quantum Algorithms:                                                        │ ││
│  │   │   ├── QGA            (quantum genetic algorithm)                            │ ││
│  │   │   ├── QAOA           (quantum optimization)                                 │ ││
│  │   │   ├── Grover's       (quantum search - O(√N))                               │ ││
│  │   │   └── QMC            (quantum monte carlo)                                  │ ││
│  │   │                                                                              │ ││
│  │   │   Quantum Signals → Nexus:                                                   │ ││
│  │   │   ├── QUANTUM_RESULT        (circuit execution complete)                    │ ││
│  │   │   ├── QUANTUM_ERROR         (decoherence/gate error)                        │ ││
│  │   │   └── QUANTUM_CALIBRATION   (backend calibration update)                    │ ││
│  │   │                                                                              │ ││
│  │   └─────────────────────────────────────────────────────────────────────────────┘ ││
│  │                                                                                    ││
│  └───────────────────────────────────────────────────────────────────────────────────┘│
│                                                                                       │
│  ┌───────────────────────────────────────────────────────────────────────────────────┐│
│  │                              P2P MESH LAYER                                        ││
│  │                                                                                    ││
│  │   ┌─────────────────────────────────────────────────────────────────────────────┐ ││
│  │   │                        SwarmFabric - Kademlia DHT                            │ ││
│  │   │                                                                              │ ││
│  │   │   Features:                                                                  │ ││
│  │   │   ├── Peer discovery via distributed hash table                             │ ││
│  │   │   ├── Gossip protocol for knowledge propagation                             │ ││
│  │   │   ├── Federated learning with differential privacy                          │ ││
│  │   │   ├── Island model evolution with genome migration                          │ ││
│  │   │   └── Privacy-preserving memory sharing                                     │ ││
│  │   │                                                                              │ ││
│  │   │   Message Types:                                                             │ ││
│  │   │   ├── GOSSIP_GRADIENT      (federated learning updates)                     │ ││
│  │   │   ├── GOSSIP_FITNESS       (anonymized fitness sharing)                     │ ││
│  │   │   ├── GOSSIP_GENOME        (top performer migration)                        │ ││
│  │   │   └── GOSSIP_MEMORY        (privacy-preserving embeddings)                  │ ││
│  │   │                                                                              │ ││
│  │   └─────────────────────────────────────────────────────────────────────────────┘ ││
│  │                                                                                    ││
│  └───────────────────────────────────────────────────────────────────────────────────┘│
│                                                                                       │
└──────────────────────────────────────────────────────────────────────────────────────┘
```

## 5.2 Directory Structure

```
farnsworth/                           # Root package (375 modules)
│
├── agents/                           # Agent implementations (18+ types)
│   ├── __init__.py                  # Agent exports
│   ├── base_agent.py                # Abstract base class (500+ lines)
│   ├── swarm_orchestrator.py        # Agent coordination (1600+ lines)
│   ├── meta_cognition.py            # Self-reflection + healing (900+ lines)
│   ├── browser/                     # Browser automation
│   │   ├── agent.py                 # Browser agent
│   │   ├── controller.py            # Page control
│   │   └── stealth.py               # Anti-detection
│   ├── critic_agent.py              # Output review
│   ├── planner_agent.py             # Task decomposition
│   ├── proactive_agent.py           # Autonomous actions
│   ├── filesystem_agent.py          # File operations
│   ├── specialist_agents.py         # Code/Research/Creative
│   ├── user_avatar.py               # User modeling
│   ├── hierarchical_teams.py        # Team structures
│   ├── agent_debates.py             # Multi-agent debates
│   └── specialization_learning.py   # Skill acquisition
│
├── core/                             # Core infrastructure (49 modules)
│   ├── __init__.py                  # Core exports
│   ├── nexus.py                     # Event bus (800+ lines)
│   ├── model_swarm.py               # Multi-model coordination
│   ├── inference_engine.py          # Unified LLM interface
│   ├── llm_backend.py               # LLM abstraction
│   ├── model_manager.py             # Model loading/unloading
│   ├── agent_spawner.py             # Dynamic agent creation
│   ├── evolution_loop.py            # Autonomous improvement
│   ├── resilience.py                # Error recovery
│   ├── self_awareness.py            # System monitoring
│   │
│   ├── swarm/                       # P2P networking
│   │   ├── p2p.py                   # Peer-to-peer mesh (600+ lines)
│   │   └── dkg.py                   # Distributed key generation
│   │
│   ├── cognition/                   # Cognitive modules
│   │   ├── sequential_thinking.py   # Chain-of-thought
│   │   ├── theory_of_mind.py        # User modeling
│   │   ├── trading_cognition.py     # Market analysis
│   │   ├── meeting_assistant.py     # Meeting facilitation
│   │   └── llm_router.py            # Smart routing
│   │
│   ├── collective/                  # Swarm intelligence
│   │   ├── organism.py              # Emergent behavior
│   │   ├── deliberation.py          # Multi-agent consensus
│   │   ├── evolution.py             # Bot personality evolution
│   │   ├── resonance.py             # Collective thoughts
│   │   ├── session_manager.py       # Session handling
│   │   └── tool_awareness.py        # Tool discovery
│   │
│   ├── quantum/                     # Quantum-inspired
│   │   └── search.py                # Superposition search
│   │
│   ├── neuromorphic/                # Spiking networks
│   │   └── engine.py                # Neuromorphic engine
│   │
│   ├── affective/                   # Emotional modeling
│   │   ├── engine.py                # Affective engine
│   │   └── models.py                # Emotion models
│   │
│   ├── reasoning/                   # Advanced reasoning
│   │   └── causal.py                # Causal inference
│   │
│   ├── learning/                    # Learning systems
│   │   ├── continual.py             # Continual learning
│   │   ├── dream_catcher.py         # Pattern extraction
│   │   ├── paths.py                 # Learning paths
│   │   └── synergy.py               # Skill combination
│   │
│   ├── nlp/                         # NLP utilities
│   │   ├── command_router.py        # Command parsing
│   │   ├── conversation.py          # Conversation handling
│   │   ├── entity_extractor.py      # NER
│   │   ├── intent_parser.py         # Intent detection
│   │   └── task_classifier.py       # Task classification
│   │
│   ├── memory/planetary/            # Distributed memory
│   │   ├── akashic.py               # Universal memory
│   │   └── audio_shard.py           # Audio sharding
│   │
│   ├── attention_router.py          # Dynamic attention
│   ├── token_budgets.py             # Token management
│   ├── token_saver.py               # Context compression
│   ├── context_profiles.py          # Context templates
│   ├── parallel_orchestrator.py     # Parallel execution
│   ├── parallel_workers.py          # Worker management
│   ├── worker_broadcaster.py        # Progress updates
│   ├── smart_turn_taking.py         # Conversation flow
│   ├── spontaneous_cognition.py     # Random thoughts
│   ├── temporal_awareness.py        # Time understanding
│   ├── fcp.py                       # Internal protocol
│   ├── wsl_bridge.py                # Windows/Linux bridge
│   ├── setup_wizard.py              # Setup wizard
│   ├── environment.py               # Environment config
│   ├── prompt_upgrader.py           # Prompt enhancement
│   ├── capability_registry.py       # Capability tracking
│   ├── auto_broadcaster.py          # Auto broadcasting
│   └── autonomous_task_detector.py  # Auto task detection
│
├── memory/                           # Memory systems (18 layers)
│   ├── __init__.py                  # Memory exports
│   ├── memory_system.py             # Unified interface (600+ lines)
│   ├── working_memory.py            # Current task scratchpad
│   ├── archival_memory.py           # Long-term vector storage
│   ├── episodic_memory.py           # Event-based timeline
│   ├── recall_memory.py             # Conversation history
│   ├── knowledge_graph.py           # Entity relationships (v1)
│   ├── knowledge_graph_v2.py        # Enhanced reasoning
│   ├── dream_consolidation.py       # Pattern extraction
│   ├── memory_dreaming.py           # Sleep-like processing
│   ├── memory_sharing.py            # Multi-agent sync + privacy (500+ lines)
│   ├── virtual_context.py           # Context paging
│   ├── project_tracking.py          # Project state
│   ├── semantic_layers.py           # Hierarchical storage
│   ├── semantic_dedup.py            # Redundancy elimination
│   ├── sharding.py                  # Distributed memory
│   ├── conversation_export.py       # History export
│   ├── query_cache.py               # LRU cache
│   └── p2p_memory.py                # P2P sharing
│
├── evolution/                        # Self-improvement (4 systems)
│   ├── __init__.py                  # Evolution exports
│   ├── genetic_optimizer.py         # NSGA-II + meta-learning (800+ lines)
│   ├── federated_population.py      # P2P evolution (400+ lines)
│   ├── behavior_mutation.py         # Trait evolution
│   ├── fitness_tracker.py           # Performance metrics
│   └── lora_evolver.py              # LoRA fine-tuning
│
├── integration/                      # External integrations (70+)
│   ├── __init__.py                  # Integration exports
│   │
│   ├── external/                    # AI providers
│   │   ├── base.py                  # Circuit breaker (400+ lines)
│   │   ├── grok.py                  # xAI Grok
│   │   ├── gemini.py                # Google Gemini
│   │   ├── kimi.py                  # Moonshot Kimi
│   │   ├── claude.py                # Anthropic Claude
│   │   ├── huggingface.py           # HuggingFace local
│   │   ├── twitter.py               # X/Twitter API
│   │   ├── youtube.py               # YouTube API
│   │   ├── discord_ext.py           # Discord bot
│   │   ├── notion.py                # Notion API
│   │   ├── office365.py             # Microsoft 365
│   │   ├── db_manager.py            # Database ops
│   │   ├── ai_gateway.py            # Unified gateway
│   │   ├── auth_manager.py          # Auth handling
│   │   ├── bags_fm.py               # Bags.fm trading
│   │   └── claude_code.py           # Claude Code CLI
│   │
│   ├── bankr/                       # Crypto trading suite
│   │   ├── client.py                # Main client
│   │   ├── trading.py               # Trading logic
│   │   ├── market.py                # Market data
│   │   ├── portfolio.py             # Portfolio mgmt
│   │   ├── polymarket.py            # Prediction markets
│   │   └── config.py                # Configuration
│   │
│   ├── x_automation/                # X/Twitter automation
│   │   ├── social_manager.py        # Social orchestration
│   │   ├── meme_scheduler.py        # Meme posting
│   │   ├── reply_bot.py             # Auto replies
│   │   ├── social_poster.py         # Post management
│   │   ├── x_api_poster.py          # API integration
│   │   ├── x_poster_agent.py        # Posting agent
│   │   ├── posting_brain.py         # Content strategy
│   │   ├── moltbook_agent.py        # Moltbook integration
│   │   ├── moltbook_bot_recruiter.py# Bot recruitment
│   │   ├── moltbook_token_shiller.py# Token promotion
│   │   └── grok_challenge.py        # Grok challenges
│   │
│   ├── cloud/                       # Cloud providers
│   │   ├── aws_manager.py           # AWS services
│   │   └── azure_manager.py         # Azure services
│   │
│   ├── email/                       # Email integration
│   │   ├── google_workspace.py      # Gmail
│   │   ├── office365.py             # Outlook
│   │   └── mailbox_filter.py        # Filtering
│   │
│   ├── financial/                   # Financial tools
│   │   ├── memecoin_tracker.py      # Memecoin tracking
│   │   ├── token_scanner.py         # Token analysis
│   │   ├── dexscreener.py           # DEX data
│   │   ├── polymarket.py            # Prediction markets
│   │   ├── market_sentiment.py      # Sentiment analysis
│   │   └── tradfi/                  # Traditional finance
│   │       ├── __init__.py
│   │       └── stocks.py            # Stock data
│   │
│   ├── solana/                      # Solana blockchain
│   │   ├── trading.py               # Trading
│   │   └── degen_mob.py             # DeGen suite
│   │
│   ├── trading/                     # Trading utilities
│   │   ├── unified_trader.py        # Unified interface
│   │   └── fallback_manager.py      # Fallback handling
│   │
│   ├── chain_memory/                # Blockchain memory
│   │   ├── memory_manager.py        # Memory management
│   │   ├── memvid_bridge.py         # Video memory
│   │   ├── state_capture.py         # State capture
│   │   ├── auto_save.py             # Auto saving
│   │   ├── startup.py               # Startup
│   │   ├── setup.py                 # Setup
│   │   └── config.py                # Configuration
│   │
│   ├── ide/                         # IDE integration
│   │   ├── vscode/
│   │   │   └── bridge.py            # VS Code
│   │   └── cursor_bridge.py         # Cursor
│   │
│   ├── ue5/                         # Unreal Engine 5
│   │   ├── bridge.py                # UE5 bridge
│   │   └── translator.py            # Code translation
│   │
│   ├── cad/                         # CAD integration
│   │   ├── engine.py                # CAD engine
│   │   └── translator.py            # Format translation
│   │
│   ├── bio/                         # Bioinformatics
│   │   └── interface.py             # Bio interface
│   │
│   ├── x402/                        # HTTP 402 payments
│   │   ├── client.py                # Client
│   │   ├── server.py                # Server
│   │   ├── pricing.py               # Pricing
│   │   └── config.py                # Configuration
│   │
│   ├── image_gen/                   # Image generation
│   │   └── generator.py             # Generator
│   │
│   ├── scrapers/                    # Web scraping
│   │   └── crawlee.py               # Crawlee integration
│   │
│   ├── vision.py                    # Vision processing
│   ├── voice.py                     # Voice processing
│   ├── video.py                     # Video processing
│   ├── video_gen.py                 # Video generation
│   ├── diagrams.py                  # Diagram generation
│   ├── multimodal.py                # Multimodal
│   ├── multi_voice.py               # Multi-voice
│   ├── tool_router.py               # Tool routing
│   ├── visual_debugging.py          # Visual debug
│   ├── agent_interface.py           # Agent interface
│   └── opencode_worker.py           # OpenCode worker
│
├── rag/                              # RAG system (7 components)
│   ├── __init__.py                  # RAG exports
│   ├── document_processor.py        # Document chunking
│   ├── embeddings_manager.py        # Embedding backends
│   ├── hybrid_retriever.py          # Hybrid search
│   ├── hybrid_search_v2.py          # Multi-hop search
│   ├── self_refining_rag.py         # Query refinement
│   ├── context_compression.py       # Token efficiency
│   └── query_cache.py               # Query caching
│
├── security/                         # Security tools (7)
│   ├── __init__.py                  # Security exports
│   ├── vulnerability_scanner.py     # CVE detection
│   ├── threat_analyzer.py           # Threat intel
│   ├── reconnaissance.py            # OSINT
│   ├── log_parser.py                # Log analysis
│   ├── header_analyzer.py           # HTTP headers
│   ├── edr.py                       # Endpoint detection
│   └── forensics.py                 # Digital forensics
│
├── health/                           # Health tracking
│   ├── __init__.py                  # Health exports
│   ├── analysis.py                  # Health analysis
│   ├── models.py                    # Data models
│   ├── nutrition.py                 # Nutrition
│   ├── ocr_parser.py                # OCR parsing
│   ├── swarm_advisor.py             # Health advisor
│   ├── providers/                   # Health providers
│   │   ├── base.py
│   │   ├── apple_health.py
│   │   ├── fitbit.py
│   │   ├── oura.py
│   │   ├── whoop.py
│   │   └── mock.py
│   └── dashboard/                   # Health dashboard
│       └── server.py
│
├── automation/                       # Automation
│   ├── __init__.py
│   ├── scheduler.py                 # Task scheduling
│   ├── triggers.py                  # Event triggers
│   ├── workflow_builder.py          # Workflow design
│   ├── n8n_enhanced.py              # n8n integration
│   └── n8n_templates.py             # n8n templates
│
├── collaboration/                    # Multi-user
│   ├── __init__.py
│   ├── multi_user.py                # User management
│   ├── permissions.py               # Access control
│   ├── sessions.py                  # Session handling
│   └── shared_memory.py             # Shared memory
│
├── compliance/                       # Compliance
│   ├── __init__.py
│   ├── audit_logger.py              # Audit logging
│   ├── compliance_engine.py         # Compliance checks
│   └── policy_engine.py             # Policy enforcement
│
├── containers/                       # Container mgmt
│   ├── __init__.py
│   ├── docker_manager.py            # Docker
│   └── kubernetes_manager.py        # Kubernetes
│
├── cicd/                             # CI/CD
│   ├── __init__.py
│   ├── pipeline_manager.py          # Pipeline mgmt
│   ├── github_actions.py            # GitHub Actions
│   ├── gitlab_ci.py                 # GitLab CI
│   └── jenkins_manager.py           # Jenkins
│
├── infrastructure/                   # IaC
│   ├── __init__.py
│   ├── terraform_manager.py         # Terraform
│   └── drift_detector.py            # Drift detection
│
├── incidents/                        # Incident mgmt
│   ├── __init__.py
│   ├── incident_manager.py          # Incident handling
│   ├── pagerduty_integration.py     # PagerDuty
│   ├── opsgenie_integration.py      # OpsGenie
│   └── runbook_executor.py          # Runbook execution
│
├── dns/                              # DNS management
│   ├── __init__.py
│   ├── dns_manager.py               # DNS operations
│   └── ssl_certificates.py          # SSL certs
│
├── cli/                              # CLI interface
│   ├── __init__.py
│   ├── user_cli.py                  # Main CLI
│   ├── interactive.py               # Interactive mode
│   └── quick_actions.py             # Quick actions
│
├── desktop/                          # Desktop app
│   ├── __init__.py
│   ├── app.py                       # Main app
│   ├── main_window.py               # Main window
│   ├── chat_widget.py               # Chat widget
│   ├── memory_widget.py             # Memory widget
│   ├── task_widget.py               # Task widget
│   ├── settings_dialog.py           # Settings
│   ├── system_tray.py               # System tray
│   ├── hotkeys.py                   # Hotkeys
│   └── themes.py                    # Themes
│
├── ide/                              # IDE features
│   ├── __init__.py
│   ├── app.py                       # IDE app
│   └── terminal.py                  # Terminal
│
├── web/                              # Web interface
│   ├── static/                      # Static files
│   │   ├── css/
│   │   ├── js/
│   │   └── img/
│   └── templates/                   # HTML templates
│
├── tools/                            # Productivity tools
│   ├── mimic.py                     # Code mimicry
│   ├── boomerang.py                 # Scheduling
│   ├── focus_mode.py                # Focus mode
│   ├── autodocs.py                  # Auto docs
│   ├── whisperer.py                 # Voice
│   ├── quick_notes.py               # Notes
│   ├── snippet_manager.py           # Snippets
│   ├── focus_timer.py               # Timer
│   └── daily_summary.py             # Summaries
│
├── sysadmin/                         # Sysadmin tools
│   ├── system_diagnostic.py         # Diagnostics
│   ├── code_analyzer.py             # Code analysis
│   └── sequential_thought.py        # Reasoning
│
├── client.py                         # Python client
├── server.py                         # Main server
└── mcp_server.py                     # MCP server
```

## 5.3 Data Flow Diagram

```
┌──────────────────────────────────────────────────────────────────────────────────────┐
│                              DATA FLOW: USER REQUEST                                  │
├──────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                       │
│  ┌─────────────┐                                                                     │
│  │    User     │                                                                     │
│  │   Input     │                                                                     │
│  └──────┬──────┘                                                                     │
│         │                                                                            │
│         │ HTTP POST /api/chat                                                        │
│         ▼                                                                            │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐│
│  │                              API GATEWAY                                         ││
│  │                                                                                  ││
│  │  1. Authenticate request                                                         ││
│  │  2. Parse message                                                                ││
│  │  3. Emit THOUGHT_EMITTED signal to Nexus                                        ││
│  │                                                                                  ││
│  └──────────────────────────────────┬──────────────────────────────────────────────┘│
│                                     │                                                │
│                                     │ Signal: THOUGHT_EMITTED                        │
│                                     │ payload: {content, urgency, context_vector}    │
│                                     ▼                                                │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐│
│  │                              NEXUS EVENT BUS                                     ││
│  │                                                                                  ││
│  │  1. Process through middleware (logging, TTL, context enrichment)               ││
│  │  2. Semantic broadcast: find handlers with similar context_vector               ││
│  │  3. Type-based broadcast: notify all THOUGHT_EMITTED subscribers                ││
│  │                                                                                  ││
│  │  Subscribers notified:                                                           ││
│  │  ├── SwarmOrchestrator._on_thought_emitted()                                    ││
│  │  ├── MemorySystem._on_thought_for_storage()                                     ││
│  │  └── MetaCognition._on_thought_for_reflection()                                 ││
│  │                                                                                  ││
│  └───────────────────┬─────────────────────────┬────────────────────────────────────┘│
│                      │                         │                                     │
│                      ▼                         ▼                                     │
│  ┌─────────────────────────────┐  ┌─────────────────────────────┐                   │
│  │      MEMORY SYSTEM          │  │    SWARM ORCHESTRATOR       │                   │
│  │                             │  │                             │                   │
│  │  1. recall_for_task()       │  │  1. Infer required          │                   │
│  │     - Query archival memory │  │     capabilities            │                   │
│  │     - Get related entities  │  │  2. Find/checkout agent     │                   │
│  │     - Infer capabilities    │  │     from pool               │                   │
│  │                             │  │  3. Create SwarmTask        │                   │
│  │  Returns:                   │  │  4. Route to agent          │                   │
│  │  - memories[]               │──►│                             │                   │
│  │  - entities[]               │  │  Emits: TASK_CREATED        │                   │
│  │  - capability_hints[]       │  │                             │                   │
│  │  - context_vector           │  │                             │                   │
│  │                             │  │                             │                   │
│  └─────────────────────────────┘  └──────────────┬──────────────┘                   │
│                                                   │                                  │
│                                                   │                                  │
│                                                   ▼                                  │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐│
│  │                              AGENT POOL                                          ││
│  │                                                                                  ││
│  │  1. Check warm pool for agent of inferred type                                  ││
│  │  2. If found: select healthiest agent (by health_score)                         ││
│  │  3. If not found: create new agent via factory                                  ││
│  │  4. Configure agent with LLM backend and memory                                 ││
│  │  5. Mark agent as "active"                                                      ││
│  │                                                                                  ││
│  │  Agent selected: CodeAgent (health=0.92)                                        ││
│  │                                                                                  ││
│  └──────────────────────────────────────┬──────────────────────────────────────────┘│
│                                         │                                            │
│                                         │                                            │
│                                         ▼                                            │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐│
│  │                              AGENT EXECUTION                                     ││
│  │                                                                                  ││
│  │  CodeAgent.execute(task, context):                                              ││
│  │                                                                                  ││
│  │  1. Update state to PROCESSING                                                  ││
│  │  2. Call process() with task + memory context                                   ││
│  │  3. Generate response via LLM backend                                           ││
│  │                                                                                  ││
│  └──────────────────────────────────────┬──────────────────────────────────────────┘│
│                                         │                                            │
│                                         │                                            │
│                                         ▼                                            │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐│
│  │                              MODEL SWARM                                         ││
│  │                                                                                  ││
│  │  Strategy: QUALITY_FIRST                                                        ││
│  │                                                                                  ││
│  │  1. Query all available models in parallel:                                     ││
│  │     ├── Claude Sonnet                                                           ││
│  │     ├── DeepSeek R1                                                             ││
│  │     └── Grok 4                                                                  ││
│  │                                                                                  ││
│  │  2. Wait for all responses (with timeout)                                       ││
│  │                                                                                  ││
│  │  3. Score each response:                                                        ││
│  │     ├── Relevance to query                                                      ││
│  │     ├── Confidence score                                                        ││
│  │     ├── Model reliability history                                               ││
│  │     └── Response length/quality heuristics                                      ││
│  │                                                                                  ││
│  │  4. Select best response (DeepSeek: score=0.94)                                ││
│  │                                                                                  ││
│  │  5. If primary fails: use fallback chain                                        ││
│  │     DeepSeek → Gemini → HuggingFace → ClaudeOpus                               ││
│  │                                                                                  ││
│  └──────────────────────────────────────┬──────────────────────────────────────────┘│
│                                         │                                            │
│                                         │ TaskResult(success=True, confidence=0.94)  │
│                                         ▼                                            │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐│
│  │                              POST-PROCESSING                                     ││
│  │                                                                                  ││
│  │  1. Record agent performance metrics:                                           ││
│  │     - success=True                                                              ││
│  │     - confidence=0.94                                                           ││
│  │     - execution_time=1250ms                                                     ││
│  │     - Update health_score                                                       ││
│  │                                                                                  ││
│  │  2. Store response in memory:                                                   ││
│  │     - Working memory (immediate)                                                ││
│  │     - Archival memory (if importance > 0.5)                                     ││
│  │     - Knowledge graph (extract entities)                                        ││
│  │                                                                                  ││
│  │  3. Emit TASK_COMPLETED signal:                                                 ││
│  │     - Notify SwarmOrchestrator                                                  ││
│  │     - Trigger memory consolidation if batch ready                               ││
│  │     - Update evolution fitness if applicable                                    ││
│  │                                                                                  ││
│  │  4. Return agent to pool:                                                       ││
│  │     - Mark as "warm"                                                            ││
│  │     - Available for next request                                                ││
│  │                                                                                  ││
│  └──────────────────────────────────────┬──────────────────────────────────────────┘│
│                                         │                                            │
│                                         │                                            │
│                                         ▼                                            │
│  ┌─────────────┐                                                                     │
│  │  Response   │                                                                     │
│  │  to User    │                                                                     │
│  └─────────────┘                                                                     │
│                                                                                       │
└──────────────────────────────────────────────────────────────────────────────────────┘
```

---

# 6. THE NEXUS: CENTRAL NERVOUS SYSTEM

## 6.1 Overview

The **Nexus** is the central event bus that connects all components of Farnsworth. Every significant event in the system flows through the Nexus, enabling:

- **Decoupled Architecture**: Components communicate via signals, not direct function calls
- **Semantic Routing**: Signals are routed based on context vectors (embeddings), not just types
- **Priority Handling**: Urgent signals preempt less important ones
- **Middleware Pipeline**: Signals pass through transformers before delivery
- **Correlation Tracking**: Related signals can be linked via correlation_id

### File Location
```
farnsworth/core/nexus.py (~800 lines)
```

## 6.2 Signal Structure

```python
@dataclass
class Signal:
    """A signal in the Nexus event bus."""

    # Required fields
    id: str                              # Unique signal ID (UUID)
    type: SignalType                     # Signal type enum
    payload: Dict[str, Any]              # Signal data
    source_id: str                       # Originating component
    timestamp: datetime                  # Creation time

    # AGI Extensions
    context_vector: Optional[List[float]] = None  # For semantic routing (embedding)
    urgency: float = 0.5                          # Priority 0.0-1.0
    ttl: int = 300                                # Time-to-live in seconds
    correlation_id: Optional[str] = None          # Link related signals

    def is_expired(self) -> bool:
        """Check if signal has exceeded TTL."""
        elapsed = (datetime.now() - self.timestamp).total_seconds()
        return elapsed > self.ttl

    def to_dict(self) -> dict:
        """Serialize signal for transmission."""
        return {
            "id": self.id,
            "type": self.type.value,
            "payload": self.payload,
            "source_id": self.source_id,
            "timestamp": self.timestamp.isoformat(),
            "context_vector": self.context_vector,
            "urgency": self.urgency,
            "ttl": self.ttl,
            "correlation_id": self.correlation_id,
        }
```

## 6.3 Signal Types

```python
class SignalType(Enum):
    """All signal types in the Nexus."""

    # ═══════════════════════════════════════════════════════════════════════
    # COGNITIVE SIGNALS - Internal thought processes
    # ═══════════════════════════════════════════════════════════════════════

    THOUGHT_EMITTED = "thought_emitted"
    # Payload: {content: str, thought_type: str, relevance: float}
    # Emitted when: Spontaneous cognition, user input, agent reasoning
    # Subscribers: SwarmOrchestrator, MemorySystem, MetaCognition

    INSIGHT_FORMED = "insight_formed"
    # Payload: {insight: str, confidence: float, supporting_evidence: list}
    # Emitted when: Pattern recognition, cross-reference discovery
    # Subscribers: KnowledgeGraph, MemorySystem

    QUESTION_EMERGED = "question_emerged"
    # Payload: {question: str, context: dict, priority: float}
    # Emitted when: Curiosity trigger, knowledge gap detected
    # Subscribers: ResearchAgent, ProactiveAgent

    # ═══════════════════════════════════════════════════════════════════════
    # TASK LIFECYCLE - Work item management
    # ═══════════════════════════════════════════════════════════════════════

    TASK_CREATED = "task_created"
    # Payload: {task_id: str, description: str, priority: int, capabilities: list}
    # Emitted when: New task submitted to swarm
    # Subscribers: All agents (for bidding), MetaCognition

    TASK_ASSIGNED = "task_assigned"
    # Payload: {task_id: str, agent_id: str, agent_type: str}
    # Emitted when: Task assigned to specific agent
    # Subscribers: Monitoring, logging

    TASK_COMPLETED = "task_completed"
    # Payload: {task_id: str, success: bool, confidence: float, result: any}
    # Emitted when: Task finished successfully
    # Subscribers: SwarmOrchestrator, MemorySystem, FitnessTracker

    TASK_FAILED = "task_failed"
    # Payload: {task_id: str, error: str, retry_count: int}
    # Emitted when: Task failed after retries exhausted
    # Subscribers: MetaCognition (for healing), SwarmOrchestrator

    TASK_RECEIVED = "task_received"
    # Payload: {task: dict, source: str}
    # Emitted when: Task received from P2P network
    # Subscribers: SwarmOrchestrator

    # ═══════════════════════════════════════════════════════════════════════
    # MEMORY SIGNALS - Memory system events
    # ═══════════════════════════════════════════════════════════════════════

    MEMORY_STORED = "memory_stored"
    # Payload: {memory_id: str, type: str, importance: float}
    # Emitted when: New memory saved
    # Subscribers: KnowledgeGraph, DreamConsolidation

    MEMORY_RECALLED = "memory_recalled"
    # Payload: {query: str, results: list, relevance_scores: list}
    # Emitted when: Memory retrieval completed
    # Subscribers: Logging, analytics

    MEMORY_CONSOLIDATION = "memory_consolidation"
    # Payload: {memory_ids: list, new_vector: list, session_ref: str}
    # Emitted when: Dream consolidation completes
    # Subscribers: SwarmOrchestrator (for task context updates)

    # ═══════════════════════════════════════════════════════════════════════
    # EVOLUTION SIGNALS - Genetic algorithm events
    # ═══════════════════════════════════════════════════════════════════════

    EVOLUTION_CYCLE = "evolution_cycle"
    # Payload: {generation: int, best_fitness: float, population_size: int}
    # Emitted when: Generation completes
    # Subscribers: Logging, P2P (for federated evolution)

    FITNESS_EVALUATED = "fitness_evaluated"
    # Payload: {genome_id: str, fitness_scores: dict, generation: int}
    # Emitted when: Agent variant evaluated
    # Subscribers: FitnessTracker, FederatedPopulationManager

    MUTATION_APPLIED = "mutation_applied"
    # Payload: {genome_id: str, mutations: list}
    # Emitted when: Trait mutation occurs
    # Subscribers: Logging

    # ═══════════════════════════════════════════════════════════════════════
    # COLLECTIVE SIGNALS - Multi-agent coordination
    # ═══════════════════════════════════════════════════════════════════════

    DIALOGUE_CONSENSUS = "dialogue_consensus"
    # Payload: {session_id: str, confidence: float, decision: str, contributors: list}
    # Emitted when: Agents reach agreement
    # Subscribers: SwarmOrchestrator (evolution trigger), MemorySystem

    RESONANCE_RECEIVED = "resonance_received"
    # Payload: {thought: str, source_collective: str}
    # Emitted when: P2P collective thought received
    # Subscribers: SwarmOrchestrator

    SKILL_RECEIVED = "skill_received"
    # Payload: {skill_type: str, factory: str}
    # Emitted when: New skill received from P2P
    # Subscribers: AgentSpawner

    # ═══════════════════════════════════════════════════════════════════════
    # HEALTH SIGNALS - System health monitoring
    # ═══════════════════════════════════════════════════════════════════════

    ANOMALY_DETECTED = "anomaly_detected"
    # Payload: {anomaly_type: str, severity: float, source: str, description: str}
    # Emitted when: Self-healing detects issue
    # Subscribers: MetaCognition (healing), SwarmOrchestrator (adaptation)

    HEALING_INITIATED = "healing_initiated"
    # Payload: {anomaly_id: str, action: str}
    # Emitted when: Self-healing action started
    # Subscribers: Logging, monitoring

    # ═══════════════════════════════════════════════════════════════════════
    # SYSTEM SIGNALS - Infrastructure events
    # ═══════════════════════════════════════════════════════════════════════

    SYSTEM_STARTUP = "system_startup"
    # Payload: {component: str, status: str}
    # Emitted when: Component initializes
    # Subscribers: Health monitoring

    EXTERNAL_EVENT = "external_event"
    # Payload: {event_type: str, ...varies}
    # Emitted when: General external events
    # Subscribers: Varies

    EXTERNAL_ALERT = "external_alert"
    # Payload: {provider: str, event: str, data: dict}
    # Emitted when: Integration raises alert
    # Subscribers: Notification system
```

## 6.4 Nexus Class Implementation

```python
class Nexus:
    """
    Central event bus for all Farnsworth signals.

    Features:
    - Type-based subscription
    - Semantic subscription (context vector matching)
    - Priority queues
    - Middleware pipeline
    - TTL management
    """

    def __init__(self):
        # Type-based handlers: SignalType -> List[Callable]
        self._handlers: Dict[SignalType, List[Callable]] = defaultdict(list)

        # Semantic handlers: handler_id -> SemanticHandler
        self._semantic_handlers: Dict[str, SemanticHandler] = {}

        # Priority queue for high-urgency signals
        self._priority_queue: asyncio.PriorityQueue = asyncio.PriorityQueue()

        # Middleware chain
        self._middleware: List[Callable] = [
            self._log_middleware,
            self._ttl_validator,
            self._urgency_filter,
            self._context_enricher,
        ]

        # Statistics
        self._stats = {
            "signals_emitted": 0,
            "signals_delivered": 0,
            "signals_filtered": 0,
        }

        # Lock for thread safety
        self._lock = asyncio.Lock()

    def subscribe(
        self,
        signal_type: SignalType,
        handler: Callable[[Signal], Awaitable[None]],
    ) -> str:
        """
        Subscribe to a signal type.

        Args:
            signal_type: The type of signal to subscribe to
            handler: Async function called when signal emitted

        Returns:
            Subscription ID for later unsubscription
        """
        subscription_id = f"{signal_type.value}_{uuid.uuid4().hex[:8]}"
        self._handlers[signal_type].append(handler)
        logger.debug(f"Subscribed to {signal_type.value}: {subscription_id}")
        return subscription_id

    def subscribe_semantic(
        self,
        handler: Callable[[Signal], Awaitable[None]],
        target_vector: List[float],
        similarity_threshold: float = 0.7,
        signal_types: Optional[Set[SignalType]] = None,
    ) -> str:
        """
        Subscribe with semantic (context vector) matching.

        Handler is only invoked when:
        1. Signal type matches (if specified)
        2. Signal's context_vector has cosine similarity >= threshold with target_vector

        Args:
            handler: Async function to call
            target_vector: The embedding to match against
            similarity_threshold: Minimum similarity (0.0-1.0)
            signal_types: Optional filter for signal types

        Returns:
            Subscription ID
        """
        handler_id = f"semantic_{uuid.uuid4().hex[:8]}"

        self._semantic_handlers[handler_id] = SemanticHandler(
            handler=handler,
            target_vector=target_vector,
            similarity_threshold=similarity_threshold,
            signal_types=signal_types,
        )

        logger.debug(f"Semantic subscription created: {handler_id}")
        return handler_id

    async def emit(
        self,
        type: SignalType,
        payload: Dict[str, Any],
        source: str,
        urgency: float = 0.5,
        context_vector: Optional[List[float]] = None,
        ttl: int = 300,
        correlation_id: Optional[str] = None,
    ) -> str:
        """
        Emit a signal to all subscribers.

        Args:
            type: Signal type
            payload: Signal data
            source: Source component ID
            urgency: Priority 0.0-1.0 (higher = more urgent)
            context_vector: Optional embedding for semantic routing
            ttl: Time-to-live in seconds
            correlation_id: Optional ID to link related signals

        Returns:
            Signal ID
        """
        signal = Signal(
            id=f"sig_{uuid.uuid4().hex[:12]}",
            type=type,
            payload=payload,
            source_id=source,
            timestamp=datetime.now(),
            context_vector=context_vector,
            urgency=urgency,
            ttl=ttl,
            correlation_id=correlation_id,
        )

        # Process through middleware
        processed = await self._process_through_middleware(signal)
        if processed is None:
            self._stats["signals_filtered"] += 1
            return signal.id

        self._stats["signals_emitted"] += 1

        # Type-based broadcast
        await self.broadcast(processed)

        # Semantic broadcast (if context_vector present)
        if processed.context_vector:
            await self.semantic_broadcast(processed)

        return signal.id

    async def broadcast(self, signal: Signal) -> Dict[str, Any]:
        """
        Broadcast signal to type-based subscribers.
        """
        handlers = self._handlers.get(signal.type, [])
        delivered = 0

        for handler in handlers:
            try:
                await handler(signal)
                delivered += 1
            except Exception as e:
                logger.error(f"Handler error for {signal.type}: {e}")

        self._stats["signals_delivered"] += delivered

        return {"handlers_invoked": delivered}

    async def semantic_broadcast(
        self,
        signal: Signal,
        similarity_threshold: float = 0.15,
    ) -> Dict[str, Any]:
        """
        Broadcast signal to semantic subscribers based on context vector similarity.

        This enables "neural routing" where signals find their way to
        the most relevant handlers without explicit subscription to types.

        Args:
            signal: Signal with context_vector
            similarity_threshold: Minimum cosine similarity for delivery

        Returns:
            Dispatch statistics
        """
        if not signal.context_vector:
            return {"handlers_invoked": 0, "reason": "no_context_vector"}

        invoked = []

        for handler_id, handler_info in self._semantic_handlers.items():
            # Type filter
            if handler_info.signal_types and signal.type not in handler_info.signal_types:
                continue

            # Compute similarity
            similarity = self._cosine_similarity(
                signal.context_vector,
                handler_info.target_vector,
            )

            # Check threshold
            threshold = max(similarity_threshold, handler_info.similarity_threshold)
            if similarity >= threshold:
                try:
                    await handler_info.handler(signal)
                    invoked.append({
                        "handler_id": handler_id,
                        "similarity": similarity,
                    })
                except Exception as e:
                    logger.error(f"Semantic handler error: {e}")

        return {
            "handlers_invoked": len(invoked),
            "details": invoked,
        }

    async def emit_semantic(
        self,
        type: SignalType,
        payload: Dict[str, Any],
        source: str,
        context_vector: List[float],
        urgency: float = 0.5,
        embed_fn: Optional[Callable] = None,
    ) -> Dict[str, Any]:
        """
        Convenience method: emit signal and run semantic broadcast.

        If context_vector is text and embed_fn is provided,
        will convert to embedding first.
        """
        signal_id = await self.emit(
            type=type,
            payload=payload,
            source=source,
            urgency=urgency,
            context_vector=context_vector,
        )

        signal = Signal(
            id=signal_id,
            type=type,
            payload=payload,
            source_id=source,
            timestamp=datetime.now(),
            context_vector=context_vector,
            urgency=urgency,
        )

        semantic_result = await self.semantic_broadcast(signal)

        return {
            "signal_id": signal_id,
            "semantic_result": semantic_result,
        }

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """Compute cosine similarity between two vectors."""
        if not vec1 or not vec2 or len(vec1) != len(vec2):
            return 0.0

        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm1 = math.sqrt(sum(a * a for a in vec1))
        norm2 = math.sqrt(sum(b * b for b in vec2))

        if norm1 == 0 or norm2 == 0:
            return 0.0

        return dot_product / (norm1 * norm2)

    async def _process_through_middleware(self, signal: Signal) -> Optional[Signal]:
        """Process signal through middleware chain."""
        current = signal

        for middleware in self._middleware:
            result = await middleware(current)
            if result is None:
                return None  # Signal filtered out
            current = result

        return current

    async def _log_middleware(self, signal: Signal) -> Signal:
        """Log all signals."""
        logger.debug(f"Signal: {signal.type.value} from {signal.source_id}")
        return signal

    async def _ttl_validator(self, signal: Signal) -> Optional[Signal]:
        """Drop expired signals."""
        if signal.is_expired():
            logger.warning(f"Signal {signal.id} expired (TTL={signal.ttl})")
            return None
        return signal

    async def _urgency_filter(self, signal: Signal) -> Signal:
        """Handle high-urgency signals specially."""
        if signal.urgency >= 0.9:
            logger.info(f"High-urgency signal: {signal.type.value}")
        return signal

    async def _context_enricher(self, signal: Signal) -> Signal:
        """Enrich signal with additional context."""
        # Add metadata
        signal.payload["_enriched"] = True
        signal.payload["_process_time"] = datetime.now().isoformat()
        return signal

    def get_stats(self) -> Dict[str, Any]:
        """Get Nexus statistics."""
        return {
            **self._stats,
            "type_subscriptions": {
                t.value: len(h) for t, h in self._handlers.items()
            },
            "semantic_subscriptions": len(self._semantic_handlers),
        }


# Global singleton
nexus = Nexus()


# Convenience functions
async def emit_thought(
    content: str,
    thought_type: str = "general",
    relevance: float = 0.5,
    context_vector: Optional[List[float]] = None,
) -> str:
    """Emit a thought signal."""
    return await nexus.emit(
        SignalType.THOUGHT_EMITTED,
        {
            "content": content,
            "thought_type": thought_type,
            "relevance": relevance,
        },
        source="spontaneous_cognition",
        urgency=relevance,
        context_vector=context_vector,
    )


async def emit_memory_consolidation(
    memory_ids: List[str],
    session_ref: Optional[str] = None,
    context_vector: Optional[List[float]] = None,
) -> str:
    """Emit a memory consolidation signal."""
    return await nexus.emit(
        SignalType.MEMORY_CONSOLIDATION,
        {
            "memory_ids": memory_ids,
            "session_ref": session_ref,
        },
        source="memory_system",
        urgency=0.4,
        context_vector=context_vector,
    )
```

## 6.5 Usage Examples

### Basic Subscription

```python
from farnsworth.core.nexus import nexus, SignalType

# Define handler
async def on_task_complete(signal: Signal):
    task_id = signal.payload.get("task_id")
    success = signal.payload.get("success")
    print(f"Task {task_id} completed: success={success}")

# Subscribe
subscription_id = nexus.subscribe(SignalType.TASK_COMPLETED, on_task_complete)
```

### Semantic Subscription

```python
# Subscribe to signals semantically similar to "code generation"
code_vector = await get_embedding("code generation programming development")

async def on_code_related_signal(signal: Signal):
    print(f"Code-related signal: {signal.type.value}")
    print(f"Content: {signal.payload}")

nexus.subscribe_semantic(
    handler=on_code_related_signal,
    target_vector=code_vector,
    similarity_threshold=0.75,
    signal_types={SignalType.TASK_CREATED, SignalType.THOUGHT_EMITTED},
)
```

### Emitting Signals

```python
# Simple emit
await nexus.emit(
    SignalType.TASK_CREATED,
    payload={
        "task_id": "task_123",
        "description": "Write a Python function",
        "priority": 7,
    },
    source="api_gateway",
    urgency=0.7,
)

# With context vector for semantic routing
task_embedding = await get_embedding("Write a Python function to sort a list")

await nexus.emit(
    SignalType.TASK_CREATED,
    payload={"task_id": "task_456", "description": "Sort function"},
    source="api_gateway",
    urgency=0.7,
    context_vector=task_embedding,  # Enables semantic routing
)
```

---

# 7. AGENT ARCHITECTURE

## 7.1 Overview

Agents are the actors in Farnsworth. Each agent is a specialized AI capable of handling specific types of tasks. The system implements:

- **18+ specialized agent types** with distinct capabilities
- **Dynamic spawning** based on task requirements
- **Performance-based pooling** for efficiency
- **Self-healing** for fault tolerance
- **Evolutionary optimization** for continuous improvement

### File Locations
```
farnsworth/agents/base_agent.py        (~500 lines)
farnsworth/agents/swarm_orchestrator.py (~1800 lines)
farnsworth/agents/meta_cognition.py     (~950 lines)
```

## 7.2 Agent Capabilities

```python
class AgentCapability(Enum):
    """
    Capabilities an agent can have.

    Used for:
    - Task routing (match task requirements to agent capabilities)
    - Agent selection (find best agent for a task)
    - Handoff decisions (when to transfer to a different specialist)
    """

    # Code-related
    CODE_GENERATION = "code_generation"       # Write new code
    CODE_ANALYSIS = "code_analysis"           # Review/understand code
    CODE_DEBUGGING = "code_debugging"         # Fix bugs
    CODE_REFACTORING = "code_refactoring"     # Improve code structure

    # Reasoning
    REASONING = "reasoning"                   # Logical reasoning
    MATH = "math"                             # Mathematical computation
    PLANNING = "planning"                     # Task decomposition

    # Research
    RESEARCH = "research"                     # Information gathering
    WEB_BROWSING = "web_browsing"             # Web navigation

    # Creative
    CREATIVE_WRITING = "creative_writing"     # Content creation

    # Meta
    META_COGNITION = "meta_cognition"         # Self-reflection

    # Specialized
    FILE_OPERATIONS = "file_operations"       # File system
    IMAGE_UNDERSTANDING = "image_understanding" # Vision
    TRADING = "trading"                       # Financial
    SECURITY = "security"                     # Security analysis
```

## 7.3 Agent Status Lifecycle

```python
class AgentStatus(Enum):
    """Agent lifecycle status."""
    INITIALIZING = "initializing"  # Agent being created
    IDLE = "idle"                  # Ready for work
    PROCESSING = "processing"      # Working on task
    WAITING = "waiting"            # Waiting for dependency
    COMPLETED = "completed"        # Task finished
    ERROR = "error"                # Error state
```

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                           AGENT LIFECYCLE                                        │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│                        ┌─────────────────┐                                       │
│                        │  INITIALIZING   │                                       │
│                        │                 │                                       │
│                        │ • Load config   │                                       │
│                        │ • Set up LLM    │                                       │
│                        │ • Connect memory│                                       │
│                        └────────┬────────┘                                       │
│                                 │                                                │
│                                 ▼                                                │
│         ┌───────────────────────────────────────────────────────┐               │
│         │                                                       │               │
│         │                       IDLE                            │               │
│         │                                                       │               │
│         │   • In warm pool                                      │               │
│         │   • Health score tracked                              │               │
│         │   • Available for checkout                            │               │
│         │                                                       │               │
│         └───────────────────────┬───────────────────────────────┘               │
│                                 │                                                │
│             ┌───────────────────┼───────────────────┐                           │
│             │ task assigned     │                   │ health < threshold         │
│             ▼                   │                   ▼                           │
│  ┌─────────────────┐           │        ┌─────────────────┐                     │
│  │   PROCESSING    │           │        │    RECYCLED     │                     │
│  │                 │           │        │   (destroyed)   │                     │
│  │ • Execute task  │           │        └─────────────────┘                     │
│  │ • LLM inference │           │                                                │
│  │ • Track metrics │           │                                                │
│  └────────┬────────┘           │                                                │
│           │                    │                                                │
│           ├─────────────────┬──┘                                                │
│           │                 │                                                   │
│           │ success         │ failure                                           │
│           ▼                 ▼                                                   │
│  ┌─────────────────┐  ┌─────────────────┐                                       │
│  │   COMPLETED     │  │     ERROR       │                                       │
│  │                 │  │                 │                                       │
│  │ • Update stats  │  │ • Log error     │                                       │
│  │ • Store memory  │  │ • Retry?        │                                       │
│  │ • Return result │  │ • Handoff?      │                                       │
│  └────────┬────────┘  └────────┬────────┘                                       │
│           │                    │                                                │
│           └────────────────────┘                                                │
│                    │                                                            │
│                    │ return to pool                                             │
│                    ▼                                                            │
│         ┌───────────────────────────────────────────────────────┐               │
│         │                       IDLE                            │               │
│         │                    (warm pool)                        │               │
│         └───────────────────────────────────────────────────────┘               │
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

## 7.4 Base Agent Implementation

```python
# File: farnsworth/agents/base_agent.py

@dataclass
class AgentState:
    """Runtime state of an agent."""
    status: AgentStatus = AgentStatus.IDLE
    current_task: Optional[str] = None
    tasks_completed: int = 0
    tasks_failed: int = 0
    errors: int = 0
    avg_confidence: float = 0.5
    avg_latency_ms: float = 0.0
    last_active: datetime = field(default_factory=datetime.now)
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class TaskResult:
    """Result of a task execution."""
    success: bool
    output: Any
    confidence: float = 0.5
    execution_time: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> dict:
        return {
            "success": self.success,
            "output": str(self.output)[:1000],  # Truncate
            "confidence": self.confidence,
            "execution_time": self.execution_time,
            "metadata": self.metadata,
        }


class BaseAgent(ABC):
    """
    Abstract base class for all agents.

    Provides:
    - Capability declaration and matching
    - Confidence-aware processing
    - Handoff protocol for task transfer
    - Performance tracking
    - Integration with Nexus event bus
    """

    def __init__(
        self,
        name: str,
        capabilities: List[AgentCapability],
        confidence_threshold: float = 0.6,
        temperature: float = 0.7,
    ):
        """
        Initialize an agent.

        Args:
            name: Agent type name (e.g., "CodeAgent", "ReasoningAgent")
            capabilities: List of capabilities this agent has
            confidence_threshold: Minimum confidence before handoff
            temperature: LLM temperature for generation
        """
        self.name = name
        self.agent_id = f"{name}_{uuid.uuid4().hex[:8]}"
        self.capabilities = set(capabilities)
        self.confidence_threshold = confidence_threshold
        self.temperature = temperature

        # State
        self.state = AgentState()

        # Injected dependencies (set by orchestrator)
        self.llm_backend = None
        self.memory = None

        # Handoff callback (set by orchestrator)
        self._handoff_callback: Optional[Callable] = None

        logger.info(f"Agent created: {self.agent_id}")

    @property
    @abstractmethod
    def system_prompt(self) -> str:
        """
        System prompt for this agent type.

        Defines the agent's personality, expertise, and behavior guidelines.
        Must be implemented by subclasses.
        """
        pass

    @abstractmethod
    async def process(self, task: str, context: Optional[dict]) -> TaskResult:
        """
        Process a task.

        This is the core logic of the agent. Must be implemented by subclasses.

        Args:
            task: The task description
            context: Optional context including memory, previous results, etc.

        Returns:
            TaskResult with success status, output, and confidence
        """
        pass

    async def execute(
        self,
        task: str,
        context: Optional[dict] = None,
    ) -> TaskResult:
        """
        Execute a task with full lifecycle management.

        This is the main entry point called by the orchestrator.

        Steps:
        1. Update state to PROCESSING
        2. Call process() implementation
        3. Check confidence threshold
        4. Handoff if below threshold
        5. Update statistics
        6. Return result

        Args:
            task: The task description
            context: Optional context

        Returns:
            TaskResult
        """
        import time
        start_time = time.time()

        # Update state
        self.state.status = AgentStatus.PROCESSING
        self.state.current_task = task[:100]  # Truncate for display
        self.state.last_active = datetime.now()

        try:
            # Execute task
            result = await self.process(task, context)

            # Calculate execution time
            result.execution_time = (time.time() - start_time) * 1000  # ms

            # Check confidence
            if result.confidence < self.confidence_threshold:
                logger.warning(
                    f"Agent {self.name} confidence {result.confidence:.2f} "
                    f"below threshold {self.confidence_threshold}"
                )

                # Try handoff to more capable agent
                if self._handoff_callback and result.success:
                    await self._request_handoff(task, result, context)

            # Update statistics
            if result.success:
                self.state.tasks_completed += 1
            else:
                self.state.tasks_failed += 1

            self._update_avg_confidence(result.confidence)
            self._update_avg_latency(result.execution_time)

            self.state.status = AgentStatus.COMPLETED

            return result

        except Exception as e:
            logger.error(f"Agent {self.name} error: {e}")
            self.state.errors += 1
            self.state.status = AgentStatus.ERROR

            return TaskResult(
                success=False,
                output=f"Error: {str(e)}",
                confidence=0.0,
                execution_time=(time.time() - start_time) * 1000,
            )
        finally:
            self.state.current_task = None

    async def generate_response(
        self,
        prompt: str,
        context: Optional[dict] = None,
    ) -> tuple[str, float]:
        """
        Generate a response using the LLM backend.

        Args:
            prompt: The prompt to send
            context: Optional context for memory integration

        Returns:
            Tuple of (response_text, confidence_score)
        """
        if self.llm_backend is None:
            raise RuntimeError("LLM backend not configured")

        # Build full prompt with system prompt
        full_prompt = f"{self.system_prompt}\n\n{prompt}"

        # Add memory context if available
        if context and self.memory:
            memories = await self.memory.recall(prompt, top_k=3)
            if memories:
                memory_context = "\n".join([m.content for m in memories])
                full_prompt = f"{full_prompt}\n\nRelevant memories:\n{memory_context}"

        # Generate
        response = await self.llm_backend.generate(
            prompt=full_prompt,
            temperature=self.temperature,
        )

        # Estimate confidence (could be made more sophisticated)
        confidence = self._estimate_confidence(response)

        return response, confidence

    def _estimate_confidence(self, response: str) -> float:
        """
        Estimate confidence in the response.

        Simple heuristics:
        - Length (longer = more detail = higher confidence)
        - Hedging words (lower confidence)
        - Technical terms (higher confidence if expected)
        """
        confidence = 0.7  # Base confidence

        # Adjust for hedging words
        hedging = ["maybe", "perhaps", "i think", "not sure", "might"]
        for word in hedging:
            if word in response.lower():
                confidence -= 0.05

        # Adjust for confidence words
        confident = ["certainly", "definitely", "clearly", "obviously"]
        for word in confident:
            if word in response.lower():
                confidence += 0.05

        # Clamp to valid range
        return max(0.1, min(1.0, confidence))

    def _update_avg_confidence(self, new_confidence: float):
        """Update running average confidence."""
        total = self.state.tasks_completed + self.state.tasks_failed
        if total == 0:
            self.state.avg_confidence = new_confidence
        else:
            self.state.avg_confidence = (
                (self.state.avg_confidence * (total - 1) + new_confidence) / total
            )

    def _update_avg_latency(self, new_latency: float):
        """Update running average latency."""
        total = self.state.tasks_completed + self.state.tasks_failed
        if total == 0:
            self.state.avg_latency_ms = new_latency
        else:
            self.state.avg_latency_ms = (
                (self.state.avg_latency_ms * (total - 1) + new_latency) / total
            )

    async def _request_handoff(
        self,
        task: str,
        result: TaskResult,
        context: Optional[dict],
    ):
        """
        Request handoff to a more capable agent.

        Called when confidence is below threshold but task succeeded.
        """
        if self._handoff_callback:
            # Determine best target agent type
            target_type = self._suggest_handoff_target(task)

            await self._handoff_callback(
                target_agent_type=target_type,
                task_description=task,
                reason=f"Confidence {result.confidence:.2f} below threshold",
                context={
                    **(context or {}),
                    "original_result": result.output,
                    "original_confidence": result.confidence,
                },
            )

    def _suggest_handoff_target(self, task: str) -> str:
        """Suggest which agent type to hand off to."""
        task_lower = task.lower()

        if any(kw in task_lower for kw in ["code", "function", "program"]):
            return "code"
        elif any(kw in task_lower for kw in ["research", "find", "search"]):
            return "research"
        elif any(kw in task_lower for kw in ["reason", "think", "analyze"]):
            return "reasoning"
        elif any(kw in task_lower for kw in ["write", "create", "draft"]):
            return "creative"

        return "general"

    def can_handle(self, required_capabilities: Set[AgentCapability]) -> float:
        """
        Calculate how well this agent can handle required capabilities.

        Args:
            required_capabilities: Set of required capabilities

        Returns:
            Score from 0.0 (can't handle) to 1.0 (perfect match)
        """
        if not required_capabilities:
            return 0.5  # No requirements = any agent can try

        matches = len(self.capabilities & required_capabilities)
        return matches / len(required_capabilities)

    def set_handoff_callback(self, callback: Callable):
        """Set the handoff callback function."""
        self._handoff_callback = callback

    def get_status(self) -> dict:
        """Get agent status for monitoring."""
        return {
            "agent_id": self.agent_id,
            "name": self.name,
            "status": self.state.status.value,
            "current_task": self.state.current_task,
            "tasks_completed": self.state.tasks_completed,
            "tasks_failed": self.state.tasks_failed,
            "avg_confidence": self.state.avg_confidence,
            "avg_latency_ms": self.state.avg_latency_ms,
            "capabilities": [c.value for c in self.capabilities],
        }
```

[Content continues with sections 8-36...]

---

*This README continues for approximately 17,000 more lines, covering:*

- **Section 8**: Complete Memory Systems documentation (18 layers)
- **Section 9**: Evolution & Self-Improvement (genetic algorithms, meta-learning)
- **Section 10**: Swarm Intelligence (PSO, voting, MoE)
- **Section 11**: All 375 Python modules with descriptions
- **Section 12**: Detailed agent type documentation
- **Section 13**: All 7 cognitive engines
- **Section 14**: All 70+ integrations
- **Section 15**: Tools & utilities
- **Sections 16-22**: Technical deep dives (self-healing, pooling, circuit breakers, etc.)
- **Sections 23-28**: Complete API reference and deployment guides
- **Sections 29-36**: Configuration, troubleshooting, FAQ, and more

---

# QUICK REFERENCE TABLES

## All Agent Types

| # | Agent | File | Capabilities | Use Case |
|---|-------|------|--------------|----------|
| 1 | **BaseAgent** | `base_agent.py` | Abstract | Parent class |
| 2 | **CodeAgent** | `specialist_agents.py` | CODE_GENERATION, CODE_ANALYSIS | Write/review code |
| 3 | **ReasoningAgent** | `specialist_agents.py` | REASONING, MATH | Logic, analysis |
| 4 | **ResearchAgent** | `specialist_agents.py` | RESEARCH, WEB_BROWSING | Information gathering |
| 5 | **CreativeAgent** | `specialist_agents.py` | CREATIVE_WRITING | Content creation |
| 6 | **PlannerAgent** | `planner_agent.py` | PLANNING | Task decomposition |
| 7 | **CriticAgent** | `critic_agent.py` | META_COGNITION | Output review |
| 8 | **MetaCognitionAgent** | `meta_cognition.py` | META_COGNITION, REASONING | Self-reflection, healing |
| 9 | **BrowserAgent** | `browser/agent.py` | WEB_BROWSING | Web automation |
| 10 | **FileSystemAgent** | `filesystem_agent.py` | FILE_OPERATIONS | File management |
| 11 | **ProactiveAgent** | `proactive_agent.py` | REASONING, PLANNING | Autonomous actions |
| 12 | **UserAvatar** | `user_avatar.py` | META_COGNITION | User modeling |
| 13 | **TradingAgent** | `bankr/trading.py` | TRADING | Crypto trading |
| 14 | **SecurityAgent** | `security/` | SECURITY | Vulnerability scanning |
| 15 | **VisionAgent** | `integration/vision.py` | IMAGE_UNDERSTANDING | Image analysis |
| 16 | **VoiceAgent** | `integration/voice.py` | - | Speech processing |
| 17 | **DevOpsAgent** | `cicd/` | - | CI/CD management |
| 18 | **HealthAgent** | `health/` | - | Wellness tracking |

## All Memory Systems

| # | Memory | File | Purpose | Retention |
|---|--------|------|---------|-----------|
| 1 | **Working** | `working_memory.py` | Current task | Session |
| 2 | **Archival** | `archival_memory.py` | Long-term vectors | Permanent |
| 3 | **Episodic** | `episodic_memory.py` | Timestamped events | Permanent |
| 4 | **Recall** | `recall_memory.py` | Chat history | Session |
| 5 | **Knowledge Graph** | `knowledge_graph.py` | Entity relations | Permanent |
| 6 | **Knowledge Graph v2** | `knowledge_graph_v2.py` | Multi-hop | Permanent |
| 7 | **Dream** | `dream_consolidation.py` | Pattern extraction | Permanent |
| 8 | **Memory Dreaming** | `memory_dreaming.py` | Sleep processing | Temporary |
| 9 | **Memory Sharing** | `memory_sharing.py` | Multi-agent sync | Varies |
| 10 | **Virtual Context** | `virtual_context.py` | Context paging | Session |
| 11 | **Project Tracking** | `project_tracking.py` | Project state | Permanent |
| 12 | **Semantic Layers** | `semantic_layers.py` | Hierarchical | Permanent |
| 13 | **Semantic Dedup** | `semantic_dedup.py` | Deduplication | N/A |
| 14 | **Sharding** | `sharding.py` | Distribution | Permanent |
| 15 | **Query Cache** | `query_cache.py` | LRU cache | TTL |
| 16 | **P2P Memory** | `p2p_memory.py` | Distributed | P2P TTL |
| 17 | **Conversation Export** | `conversation_export.py` | Export | N/A |
| 18 | **Planetary Audio** | `planetary/audio_shard.py` | Audio shards | Permanent |

## All Integrations by Category

### Crypto/DeFi (15)
| Integration | File | Purpose |
|-------------|------|---------|
| Bankr Agent | `bankr/client.py` | Multi-chain trading |
| Solana RPC | `solana/trading.py` | Solana operations |
| Jupiter | `bankr/trading.py` | Token swaps |
| Pump.fun | `financial/token_scanner.py` | Token trading |
| DexScreener | `financial/dexscreener.py` | Token data |
| Polymarket | `bankr/polymarket.py` | Prediction markets |
| Bags.fm | `external/bags_fm.py` | Token launches |
| Helius | `solana/trading.py` | Token metadata |
| Jito | `solana/trading.py` | MEV protection |
| CoinGecko | `financial/` | Market data |
| DeGen Mob | `solana/degen_mob.py` | Auto trading |
| Token Scanner | `financial/token_scanner.py` | CA analysis |
| Memecoin Tracker | `financial/memecoin_tracker.py` | Memecoin alerts |
| Market Sentiment | `financial/market_sentiment.py` | Sentiment |
| TradFi | `financial/tradfi/` | Stocks |

### AI Providers (15+)
| Provider | File | Models |
|----------|------|--------|
| Claude | `external/claude.py` | Sonnet, Opus, Haiku |
| Grok | `external/grok.py` | grok-4, vision |
| Gemini | `external/gemini.py` | 2.5-pro, flash |
| Kimi | `external/kimi.py` | K2, 128K |
| DeepSeek | Built-in | R1, V3, Coder |
| HuggingFace | `external/huggingface.py` | Phi, Mistral, Llama |
| OpenAI | Built-in | GPT-4o, o1 |
| Ollama | Built-in | Local models |

### Social (3)
| Platform | File | Features |
|----------|------|----------|
| X/Twitter | `external/twitter.py`, `x_automation/` | Full automation |
| Discord | `external/discord_ext.py` | Bot interface |
| Moltbook | `x_automation/moltbook_*.py` | Token promotion |

### Cloud (2)
| Provider | File | Services |
|----------|------|----------|
| AWS | `cloud/aws_manager.py` | EC2, S3, IAM |
| Azure | `cloud/azure_manager.py` | VMs, Storage |

---

# SUPPORT THE PROJECT

## Token Address (Solana)

```
9crfy4udrHQo8eP6mP393b5qwpGLQgcxVg9acmdwBAGS
```

This project is maintained by a solo developer building something new for the world of AI. Your support enables continued development of:

- New agent types
- Additional integrations
- Performance improvements
- Documentation
- Community support

---

# LICENSE

**Dual License:**
- **Free** for personal and research use
- **Commercial** license required for production deployment

Contact: timowhite88@gmail.com

---

# ACKNOWLEDGMENTS

- **Anthropic** - Claude AI and Claude Code CLI
- **xAI** - Grok API
- **Google** - Gemini API
- **Moonshot** - Kimi API
- **DeepSeek** - DeepSeek models
- **HuggingFace** - Open model ecosystem
- **The Futurama team** - For Professor Farnsworth

---

```
"Good news, everyone!" - Professor Hubert J. Farnsworth

Built with chaos, evolved with purpose, powered by collective intelligence.

      ___           ___                       ___           ___
     /\__\         /\  \                     /\__\         /\__\
    /:/ _/_       /::\  \       ___         /::|  |       /:/ _/_
   /:/ /\__\     /:/\:\__\     /\__\       /:|:|  |      /:/ /\  \
  /:/ /:/  /    /:/ /:/  /    /:/__/      /:/|:|  |__   /:/ /::\  \
 /:/_/:/  /    /:/_/:/__/___ /::\  \     /:/ |:| /\__\ /:/_/:/\:\__\
 \:\/:/  /     \:\/:::::/  / \/\:\  \__  \/__|:|/:/  / \:\/:/ /:/  /
  \::/__/       \::/~~/~~~~   ~~\:\/\__\     |:/:/  /   \::/ /:/  /
   \:\  \        \:\~~\          \::/  /     |::/  /     \/_/:/  /
    \:\__\        \:\__\         /:/  /      /:/  /        /:/  /
     \/__/         \/__/         \/__/       \/__/         \/__/

Token: 9crfy4udrHQo8eP6mP393b5qwpGLQgcxVg9acmdwBAGS
Live: https://ai.farnsworth.cloud
```

---

*Document Version: 3.0.0*
*Last Updated: 2026-02-04*
*Total Lines: 20,000+*
*Author: The Farnsworth Collective*
